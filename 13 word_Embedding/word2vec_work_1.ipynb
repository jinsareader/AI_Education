{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce0d106-de1d-4dfe-b807-8a56700ccb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"\"),\"..\"))\n",
    "\n",
    "import custom\n",
    "import numpy\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77629bb-49ea-421c-81ed-168ab7bb1a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9616\n"
     ]
    }
   ],
   "source": [
    "with open(\"ptb.train.txt\") as f:\n",
    "    text = f.readlines()\n",
    "word_dict, number_dict = custom.make_dict(text)\n",
    "print(len(word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a4cb41-8009-4914-ab51-be1f7ccf182a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    3    4 ...    0    0    0]\n",
      " [  28   29   30 ...    0    0    0]\n",
      " [  42   29   43 ...    0    0    0]\n",
      " ...\n",
      " [4322 4919   38 ...    0    0    0]\n",
      " [  81  831   33 ...    0    0    0]\n",
      " [ 112 3581 3582 ...    0    0    0]]\n",
      "(42068, 98)\n"
     ]
    }
   ],
   "source": [
    "corpus = custom.word_num_encoding(text, word_dict)\n",
    "print(corpus)\n",
    "print(corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187c54de-f2b8-498c-b438-651bc2fdde1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   3]\n",
      " [  2   4]\n",
      " [  3   2]\n",
      " ...\n",
      " [ 42 260]\n",
      " [ 29  42]\n",
      " [ 29  67]]\n",
      "(3295980, 2)\n"
     ]
    }
   ],
   "source": [
    "word_pair = custom.make_word_pair(corpus, window_size=2)\n",
    "print(word_pair)\n",
    "print(word_pair.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ed2ec5-d256-4068-abc4-ab347f3f4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tensor_x = torch.tensor(word_pair[:,0], dtype = torch.long, device = device)\n",
    "tensor_t = torch.tensor(word_pair[:,1], dtype = torch.long, device = device)\n",
    "zip_list = list(zip(tensor_x, tensor_t))\n",
    "dataloader = DataLoader(zip_list,batch_size=100000,shuffle=True)\n",
    "\n",
    "tensor_x = None\n",
    "tensor_t = None\n",
    "zip_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1febe2d5-4dae-4ea0-8105-0450b6b0b622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | loss 8.662688255310059\n",
      "epoch 2 | loss 8.619721412658691\n",
      "epoch 3 | loss 8.577051162719727\n",
      "epoch 4 | loss 8.53458309173584\n",
      "epoch 5 | loss 8.492337226867676\n",
      "epoch 6 | loss 8.450299263000488\n",
      "epoch 7 | loss 8.408536911010742\n",
      "epoch 8 | loss 8.367045402526855\n",
      "epoch 9 | loss 8.32580280303955\n",
      "epoch 10 | loss 8.284808158874512\n",
      "epoch 11 | loss 8.24405574798584\n",
      "epoch 12 | loss 8.203537940979004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class NN(nn.Module) :\n",
    "    def __init__(self, word_size) :\n",
    "        super().__init__();\n",
    "        self.f = nn.Embedding(word_size, 100, max_norm=1, padding_idx=0)\n",
    "        self.g = nn.Linear(100, word_size)\n",
    "    def forward(self, x) :\n",
    "        y = self.f(x)\n",
    "        y = self.g(y)\n",
    "        return y\n",
    "\n",
    "F = NN(len(word_dict))\n",
    "F = F.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(F.parameters())\n",
    "epoch = 100\n",
    "\n",
    "for e in range(epoch) :\n",
    "    loss_sum = 0\n",
    "    for x, t in dataloader :\n",
    "        y = F(t)\n",
    "    \n",
    "        loss = loss_function(y, t)\n",
    "        loss_sum += loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    loss_sum /= len(dataloader)\n",
    "    \n",
    "    if (e+1) % 1 == 0 :\n",
    "        print(\"epoch {} | loss {}\".format(e+1, loss_sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da135f-602b-4146-a225-809422a37101",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.to(\"cpu\")\n",
    "word_vecs = F.state_dict()['f.weight'].numpy()\n",
    "\n",
    "print(word_vecs.shape)\n",
    "print(word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8333489e-b8ed-463a-81a2-ef638ad253eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = word_vecs.tolist()\n",
    "vector_dict = {}\n",
    "words = list(word_dict.keys())\n",
    "\n",
    "for i in (len(word_vecs))\n",
    "    vector_dict[words[i]] = word_vecs[i]\n",
    "\n",
    "print(vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225d6ae-3be8-4625-b4fe-b87ca9abc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"word2vec_vector.pkl\", mode = \"wb\") as f :\n",
    "    pickle.dump(word_vecs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
