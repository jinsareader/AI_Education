{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae1c19f-ee75-4fa5-b9d2-8c5545704675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"\"),\"..\"))\n",
    "\n",
    "import custom\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f11dd44-fa40-41b9-86f4-f82b2dc5292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_tensor):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_tensor, freeze=True, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embedding_tensor.shape[1], embedding_tensor.shape[1], batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.flip(x, [-1])\n",
    "        x = self.embedding(x)\n",
    "        output, hc = self.rnn(x)\n",
    "        return output, hc\n",
    "\n",
    "class Decoder(nn.Module) :\n",
    "    def __init__(self, embedding_tensor):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_tensor, freeze=True, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embedding_tensor.shape[1] * 3, embedding_tensor.shape[1], batch_first=True, bidirectional=True)\n",
    "        self.f = nn.Linear(embedding_tensor.shape[1] * 4, embedding_tensor.shape[0])\n",
    "        self.encoder_h_context = None\n",
    "\n",
    "    def forward(self, encoder_output, encoder_hc, t = None) :\n",
    "        encoder_h_forward = encoder_hc[0][0:1,:,:]\n",
    "        encoder_h_backward = encoder_hc[0][1:2,:,:]\n",
    "        self.encoder_h_context = torch.concat([encoder_h_forward,encoder_h_backward], dim = -1).transpose(0,1)\n",
    "        batch_size = encoder_output.shape[0]\n",
    "        decoder_input = torch.zeros(batch_size, 1).type(torch.long).to(encoder_output.device)\n",
    "        decoder_hc = encoder_hc\n",
    "        decoder_output_list = []\n",
    "\n",
    "        for i in range(4) :\n",
    "            decoder_output, decoder_hc = self.forward_sub(decoder_input, decoder_hc)\n",
    "            decoder_output_list.append(decoder_output)\n",
    "\n",
    "            if t is None :\n",
    "                decoder_input = decoder_output.argmax(dim = -1).detach()\n",
    "            else :\n",
    "                decoder_input = t[:, i].unsqueeze(-1)\n",
    "\n",
    "        decoder_output_list = torch.cat(decoder_output_list, dim=1)\n",
    "        return decoder_output_list, decoder_hc, None\n",
    "\n",
    "    def forward_sub(self, x, h) :\n",
    "        x = self.embedding(x)\n",
    "        x = torch.concat([self.encoder_h_context, x], dim = -1)\n",
    "        output, hc = self.rnn(x, h)\n",
    "        output = torch.concat([self.encoder_h_context, output], dim = -1)\n",
    "        output = self.f(output)\n",
    "        return output, hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f995fa71-4af4-42ae-8f4e-e70deeaf1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "encoder = torch.load(\"num_encoder.pt\", weights_only=False)\n",
    "decoder = torch.load(\"num_decoder.pt\", weights_only=False)\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e613fcc9-8bdf-45ea-87df-c3e441149698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "식을 입력하세요 (최대 길이 7) :  종료\n"
     ]
    }
   ],
   "source": [
    "dic = {' ': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '0': 10, '+': 11}\n",
    "query = None\n",
    "\n",
    "while True :\n",
    "    query = input(\"식을 입력하세요 (최대 길이 7) : \")\n",
    "    if query == \"종료\" :\n",
    "        break\n",
    "    query = re.sub(r\"[^0-9+]\", \"\", string = query)\n",
    "    query = list(query)\n",
    "    query = custom.word_vectorize(query, dic, 7, False, \" \", \" \")\n",
    "    query = [query]\n",
    "    tensor = torch.tensor(query, dtype = torch.long, device = device)\n",
    "    y, h = encoder(tensor)\n",
    "    ys, _, _ = decoder(y, h)\n",
    "    for y in ys[0] :\n",
    "        print(list(dic.keys())[y.argmax(dim = -1).item()], end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34af78-2299-49f3-aef8-3b31c245b168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
