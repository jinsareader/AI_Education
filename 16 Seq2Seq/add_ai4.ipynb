{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5319f009-ecce-41f7-957d-c120299e80de",
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1748693177832,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "5319f009-ecce-41f7-957d-c120299e80de"
   },
   "outputs": [],
   "source": [
    "# 덧셈만 하는 deeplearing ai 만들기\n",
    "# 숫자값을 int가 아니라 str 문자 하나로 생각해서 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e04307-1813-4cea-a87a-df93604caf0b",
   "metadata": {
    "executionInfo": {
     "elapsed": 2724,
     "status": "ok",
     "timestamp": 1748693181870,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "63e04307-1813-4cea-a87a-df93604caf0b"
   },
   "outputs": [],
   "source": [
    "#필요한 module import\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"\"), \"..\"))\n",
    "\n",
    "import custom\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f83ec98-fbb2-4551-b35e-3b27cc02af92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1748693181888,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "1f83ec98-fbb2-4551-b35e-3b27cc02af92",
    "outputId": "1db60799-a931-4861-bb3a-3332531228d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기 전에 원핫 인코딩 리스트, 숫자-라벨링 사전 두개 만들어서 원핫 인코딩 리스트는 신경망 안에 집어넣기\n",
    "#[' ',1,2,3,4,5,6,7,8,9,0,+]\n",
    "\n",
    "#원한 인코딩 리스트\n",
    "embedding_tensor = torch.cat([torch.zeros(1,11), torch.eye(11)])\n",
    "#torch.zeros : 파라미터 크기의 0텐서 생성\n",
    "#torch.eye : 정사각 단위행렬 (대각선이 1이고 나머진 0인 행렬) 생성\n",
    "print(embedding_tensor)\n",
    "#0번째 : 공백(padding), 1~10번째 : 1~0, 11번째 : +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272801aa-1a6d-44d7-94e4-e861293f421a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1748693181906,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "272801aa-1a6d-44d7-94e4-e861293f421a",
    "outputId": "44fdffc5-7a4a-4122-9108-d346d4f88cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '0': 10, '+': 11}\n"
     ]
    }
   ],
   "source": [
    "#숫자 문자 - 라벨링 사전\n",
    "\n",
    "num_dict = {}\n",
    "\n",
    "num_dict[\" \"] = 0\n",
    "for i in range(1,10) :\n",
    "    num_dict[str(i)] = i\n",
    "num_dict[\"0\"] = 10\n",
    "num_dict[\"+\"] = 11\n",
    "\n",
    "print(num_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0be3001-ded7-41d4-b911-7ded0cda4a7a",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1748693181923,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "f0be3001-ded7-41d4-b911-7ded0cda4a7a"
   },
   "outputs": [],
   "source": [
    "# 데이터 읽어오기\n",
    "\n",
    "with open(\"addition.txt\", mode = \"r\") as f:\n",
    "    ori_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd19ef0-fc32-4a0b-9bfe-0e61af7018ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1748693182010,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "fcd19ef0-fc32-4a0b-9bfe-0e61af7018ac",
    "outputId": "aaecc7d3-6a0b-4b8f-eb35-71b156a0b0e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 갯수 :  50000\n",
      "x문자의 갯수 :  7\n",
      "x를 문자로 나눈 것 :  ['1', '8', '+', '8', ' ', ' ', ' ']\n",
      "t의 갯수 :  50000\n",
      "t문자의 갯수 :  4\n",
      "t를 문자로 나눈 것 :  ['2', '6', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "# 데이터 x, t로 나누기\n",
    "data = ori_data.split(\"\\n\")\n",
    "\n",
    "x = []\n",
    "t = []\n",
    "for nums in data :\n",
    "    if nums.find(\"_\") < 0 :\n",
    "        continue\n",
    "    nums = nums.split(\"_\") # _를 기준으로 나누고\n",
    "    x.append(nums[0]) #앞의 입력값\n",
    "    t.append(nums[1]) #뒤의 출력값\n",
    "\n",
    "print(\"x의 갯수 : \", len(x))\n",
    "print(\"x문자의 갯수 : \", len(x[10]))\n",
    "print(\"x를 문자로 나눈 것 : \", list(x[10]))\n",
    "\n",
    "print(\"t의 갯수 : \", len(t))\n",
    "print(\"t문자의 갯수 : \", len(t[10]))\n",
    "print(\"t를 문자로 나눈 것 : \", list(t[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a09aa76-0560-4dae-a3ab-926832033360",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1748693182345,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "5a09aa76-0560-4dae-a3ab-926832033360",
    "outputId": "e1ba0abf-dc4a-4633-caa6-23874d6f827e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 모양 :  (50000, 7)\n",
      "10번째 라벨값 :  [ 1  8 11  8  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "#x 문자들을 라벨링\n",
    "vector_x = []\n",
    "for i in range(len(x)) :\n",
    "    temp = list(x[i]) #str을 문자단위로 끊은 list로 바꾸기\n",
    "    vector = custom.word_vectorize(temp, num_dict)\n",
    "    vector_x.append(vector)\n",
    "\n",
    "vector_x = np.array(vector_x)\n",
    "print(\"x 모양 : \", vector_x.shape)\n",
    "print(\"10번째 라벨값 : \", vector_x[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9144ca76-8aab-4a85-a70c-5400e7ce2ced",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1748693182870,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "9144ca76-8aab-4a85-a70c-5400e7ce2ced",
    "outputId": "d8f71773-ca39-4f82-9c48-6abec063d199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 모양 :  (50000, 4)\n",
      "10번째 라벨값 :  [2 6 0 0]\n"
     ]
    }
   ],
   "source": [
    "#t 문자들을 라벨링 (출력값 y와 비교하기 위해서)\n",
    "vector_t = []\n",
    "for i in range(len(t)) :\n",
    "    temp = list(t[i])\n",
    "    vector = custom.word_vectorize(temp, num_dict)\n",
    "    vector_t.append(vector)\n",
    "\n",
    "vector_t = np.array(vector_t)\n",
    "print(\"t 모양 : \", vector_t.shape)\n",
    "print(\"10번째 라벨값 : \", vector_t[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8967e8ef-9548-4942-b555-acd47f4de879",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1340,
     "status": "ok",
     "timestamp": 1748693184212,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "8967e8ef-9548-4942-b555-acd47f4de879",
    "outputId": "af11280c-4423-48bc-9e0b-68f6063dbcd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# 전처리한 데이터 x, t를 DataLoader에 싣기\n",
    "# train, test 나누겠습니다. 앞의 40000개는 train, 뒤의 10000개는 test\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "s = 40000\n",
    "\n",
    "tensor_x = torch.tensor(vector_x, dtype = torch.long, device = device)\n",
    "tensor_t = torch.tensor(vector_t, dtype = torch.long, device = device)\n",
    "\n",
    "train_zip_list = list(zip(tensor_x[:s], tensor_t[:s]))\n",
    "test_zip_list = list(zip(tensor_x[s:], tensor_t[s:]))\n",
    "\n",
    "train_dataloader = DataLoader(train_zip_list, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(test_zip_list, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fccf2adf-7710-40f5-847b-2ede81ab1f94",
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1748693184251,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "fccf2adf-7710-40f5-847b-2ede81ab1f94"
   },
   "outputs": [],
   "source": [
    "# 함수들 만들기\n",
    "class Encoder(nn.Module) :\n",
    "    def __init__(self, embedding_vector) :\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_vector, freeze = True, padding_idx = 0) # 라벨값을 벡터로 바꾸는 Embedding 함수\n",
    "        self.rnn = nn.LSTM(embedding_vector.shape[1], embedding_vector.shape[1], batch_first = True, bidirectional = True) #임베딩 열 크기를 받아서 임베딩 열 크기를 출력\n",
    "    def forward(self, x) :\n",
    "        x = self.embedding(x)\n",
    "        y, hc = self.rnn(x)\n",
    "        return y, hc\n",
    "\n",
    "class Decoder(nn.Module) :\n",
    "    def __init__(self, embedding_vector) :\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_vector, freeze = True, padding_idx = 0)\n",
    "        self.rnn = nn.LSTM(embedding_vector.shape[1] * 3, embedding_vector.shape[1], batch_first = True, bidirectional = True)\n",
    "        self.f = nn.Linear(embedding_vector.shape[1] * 4, embedding_vector.shape[0]) #RNN을 계산하고 난 뒤 벡터값을 다시 라벨값으로 바꾸는 용도, 단어 출력 용도\n",
    "        self.encoder_h_context = None #encoder_h 가공값 저장할 변수\n",
    "    def forward(self, encoder_output, encoder_hc, t = None) : #문장 여러개 처리하기 위해서 encoder_output.shape가 필요함\n",
    "        #decoder 학습 방법 2가지 (greedy, teaching_force)\n",
    "        #encoder_h 가공\n",
    "        encoder_h_forward = encoder_hc[0][0:1,:,:]\n",
    "        encoder_h_backward = encoder_hc[0][1:2,:,:] #encoder의 h값 반으로 쪼개기\n",
    "        self.encoder_h_context = torch.concat([encoder_h_forward, encoder_h_backward], dim = -1).transpose(0,1) #peeky algorithm, 적용하기 위한 변수\n",
    "\n",
    "        batch_size = encoder_output.shape[0] #문장 갯수 정하기 = encoder에서 처리한 문장 갯수\n",
    "        decoder_input = torch.zeros(batch_size, 1).type(torch.long).to(encoder_output.device) #처음 넣는 단어 (0번째 단어인 padding)\n",
    "        decoder_hc = encoder_hc\n",
    "        decoder_output_list = [] #단어들 모아서 문장으로 만들어 출력\n",
    "\n",
    "        for i in range(4) : #t의 문자갯수만큼 반복\n",
    "            decoder_output, decoder_hc = self.forward_cal(decoder_input, decoder_hc)\n",
    "            decoder_output_list.append(decoder_output)\n",
    "\n",
    "            if t is None : #greedy (t가 없음)\n",
    "                decoder_input = decoder_output.argmax(dim = -1).detach()\n",
    "            else : #teaching-force (t가 있음)\n",
    "                decoder_input = t[:, i:i+1]\n",
    "\n",
    "        decoder_output_list = torch.cat(decoder_output_list, dim = 1) #for 문 종료 후 list로 모아놓은 tensor들을 tensor로 합치는 작업\n",
    "        return decoder_output_list, decoder_hc, None\n",
    "\n",
    "    def forward_cal(self, x, hc) : #실제 신경망 계산 함수\n",
    "        x = self.embedding(x) #라벨을 벡터로\n",
    "        x = torch.concat([self.encoder_h_context, x], dim = -1) #peeky algorithm 적용\n",
    "        output, hc = self.rnn(x, hc) #처음 h값을 지정하고 싶으면 x 뒤에 h값 입력하세요\n",
    "        output = torch.concat([self.encoder_h_context, output], dim = -1) #peeky algorithm 적용\n",
    "        output = self.f(output) #벡터 계산값을 다시 라벨값으로 변환\n",
    "        return output, hc\n",
    "\n",
    "class NN(nn.Module) :\n",
    "    def __init__(self, embedding_vector) :\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(embedding_vector)\n",
    "        self.decoder = Decoder(embedding_vector)\n",
    "\n",
    "    def forward(self, x, t = None) :\n",
    "        y, hc = self.encoder(x)\n",
    "        y, _, _ = self.decoder(y, hc, t)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebcddf0d-a2ee-4a1c-be54-b30bacdd43a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 358297,
     "status": "ok",
     "timestamp": 1748693542550,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "ebcddf0d-a2ee-4a1c-be54-b30bacdd43a7",
    "outputId": "84708e3a-663c-4874-97f2-95029f4e2535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | loss 1.6400350984930991 | acc 0.42365 | cnt 0\n",
      "epoch 2 | loss 1.2298963162302972 | acc 0.509275 | cnt 0\n",
      "epoch 3 | loss 1.0842565636336803 | acc 0.550125 | cnt 0\n",
      "epoch 4 | loss 1.004134060293436 | acc 0.573525 | cnt 0\n",
      "epoch 5 | loss 0.957339731901884 | acc 0.585225 | cnt 0\n",
      "epoch 6 | loss 0.9183915151655674 | acc 0.595075 | cnt 0\n",
      "epoch 7 | loss 0.8895686495304108 | acc 0.6096 | cnt 0\n",
      "epoch 8 | loss 0.8710586734116077 | acc 0.618425 | cnt 0\n",
      "epoch 9 | loss 0.8432690761983395 | acc 0.625 | cnt 0\n",
      "epoch 10 | loss 0.8256641478836536 | acc 0.619175 | cnt 1\n",
      "epoch 11 | loss 0.8075960864126682 | acc 0.6392 | cnt 0\n",
      "epoch 12 | loss 0.7897440904378891 | acc 0.62925 | cnt 1\n",
      "epoch 13 | loss 0.7750884269177913 | acc 0.64715 | cnt 0\n",
      "epoch 14 | loss 0.7524833415448665 | acc 0.632125 | cnt 1\n",
      "epoch 15 | loss 0.7296978421509266 | acc 0.646875 | cnt 2\n",
      "epoch 16 | loss 0.7101143196225166 | acc 0.658675 | cnt 0\n",
      "epoch 17 | loss 0.6860982491075993 | acc 0.6767 | cnt 0\n",
      "epoch 18 | loss 0.6656250721216201 | acc 0.6739 | cnt 1\n",
      "epoch 19 | loss 0.644703414440155 | acc 0.67765 | cnt 0\n",
      "epoch 20 | loss 0.6293554995954037 | acc 0.6898 | cnt 0\n",
      "epoch 21 | loss 0.6136972622573376 | acc 0.693225 | cnt 0\n",
      "epoch 22 | loss 0.5978133160620928 | acc 0.69585 | cnt 0\n",
      "epoch 23 | loss 0.5831416100263596 | acc 0.703 | cnt 0\n",
      "epoch 24 | loss 0.5701367300748825 | acc 0.719175 | cnt 0\n",
      "epoch 25 | loss 0.5533240094035864 | acc 0.7193 | cnt 0\n",
      "epoch 26 | loss 0.5440721101313829 | acc 0.72655 | cnt 0\n",
      "epoch 27 | loss 0.5293105524778366 | acc 0.728 | cnt 0\n",
      "epoch 28 | loss 0.5194356647878885 | acc 0.739525 | cnt 0\n",
      "epoch 29 | loss 0.5093928215652704 | acc 0.7247 | cnt 1\n",
      "epoch 30 | loss 0.4956460214406252 | acc 0.745575 | cnt 0\n",
      "epoch 31 | loss 0.4897134516388178 | acc 0.7427 | cnt 1\n",
      "epoch 32 | loss 0.4805131635069847 | acc 0.749275 | cnt 0\n",
      "epoch 33 | loss 0.4675920531153679 | acc 0.764675 | cnt 0\n",
      "epoch 34 | loss 0.4602473698556423 | acc 0.758775 | cnt 1\n",
      "epoch 35 | loss 0.4539471847563982 | acc 0.75575 | cnt 2\n",
      "epoch 36 | loss 0.44057004146277906 | acc 0.769225 | cnt 0\n",
      "epoch 37 | loss 0.43279417775571344 | acc 0.77235 | cnt 0\n",
      "epoch 38 | loss 0.4221277188509703 | acc 0.76685 | cnt 1\n",
      "epoch 39 | loss 0.41259684041142464 | acc 0.7797 | cnt 0\n",
      "epoch 40 | loss 0.41297225065529347 | acc 0.79265 | cnt 0\n",
      "epoch 41 | loss 0.39470899909734725 | acc 0.789825 | cnt 1\n",
      "epoch 42 | loss 0.3830816745012999 | acc 0.800425 | cnt 0\n",
      "epoch 43 | loss 0.3844656904041767 | acc 0.812175 | cnt 0\n",
      "epoch 44 | loss 0.3748979564756155 | acc 0.8135 | cnt 0\n",
      "epoch 45 | loss 0.3622083905339241 | acc 0.8188 | cnt 0\n",
      "epoch 46 | loss 0.3546140237897635 | acc 0.819825 | cnt 0\n",
      "epoch 47 | loss 0.3480859675258398 | acc 0.791775 | cnt 1\n",
      "epoch 48 | loss 0.33781700126826764 | acc 0.8249 | cnt 0\n",
      "epoch 49 | loss 0.33533622436225413 | acc 0.835375 | cnt 0\n",
      "epoch 50 | loss 0.3301954207569361 | acc 0.824475 | cnt 1\n",
      "epoch 51 | loss 0.31986791163682937 | acc 0.834325 | cnt 2\n",
      "epoch 52 | loss 0.3099375059455633 | acc 0.8471 | cnt 0\n",
      "epoch 53 | loss 0.3064560517296195 | acc 0.839925 | cnt 1\n",
      "epoch 54 | loss 0.3005858736485243 | acc 0.857025 | cnt 0\n",
      "epoch 55 | loss 0.2966926746070385 | acc 0.85105 | cnt 1\n",
      "epoch 56 | loss 0.2886075658723712 | acc 0.85775 | cnt 0\n",
      "epoch 57 | loss 0.27865123756229876 | acc 0.853825 | cnt 1\n",
      "epoch 58 | loss 0.2757878865301609 | acc 0.86165 | cnt 0\n",
      "epoch 59 | loss 0.2727012039348483 | acc 0.862475 | cnt 0\n",
      "epoch 60 | loss 0.2660719333961606 | acc 0.86785 | cnt 0\n",
      "epoch 61 | loss 0.2654624243825674 | acc 0.879925 | cnt 0\n",
      "epoch 62 | loss 0.2508105478435755 | acc 0.86995 | cnt 1\n",
      "epoch 63 | loss 0.25088525269180534 | acc 0.866375 | cnt 2\n",
      "epoch 64 | loss 0.24595131654292346 | acc 0.88905 | cnt 0\n",
      "epoch 65 | loss 0.24089221697300672 | acc 0.8882 | cnt 1\n",
      "epoch 66 | loss 0.2351786970719695 | acc 0.888525 | cnt 2\n",
      "epoch 67 | loss 0.23196284826844932 | acc 0.8806 | cnt 3\n",
      "epoch 68 | loss 0.22693330351263286 | acc 0.8898 | cnt 0\n",
      "epoch 69 | loss 0.2192904629558325 | acc 0.891525 | cnt 0\n",
      "epoch 70 | loss 0.21654395151883363 | acc 0.896875 | cnt 0\n",
      "epoch 71 | loss 0.21001115266233683 | acc 0.88885 | cnt 1\n",
      "epoch 72 | loss 0.2043671291694045 | acc 0.90005 | cnt 0\n",
      "epoch 73 | loss 0.22076287388801574 | acc 0.890875 | cnt 1\n",
      "epoch 74 | loss 0.19667173836380245 | acc 0.9074 | cnt 0\n",
      "epoch 75 | loss 0.20618507761508226 | acc 0.906 | cnt 1\n",
      "epoch 76 | loss 0.19546857399865986 | acc 0.9067 | cnt 2\n",
      "epoch 77 | loss 0.18830771587789058 | acc 0.904025 | cnt 3\n",
      "epoch 78 | loss 0.18848088797181844 | acc 0.912825 | cnt 0\n",
      "epoch 79 | loss 0.17814175475388766 | acc 0.9213 | cnt 0\n",
      "epoch 80 | loss 0.19107426268979907 | acc 0.89945 | cnt 1\n",
      "epoch 81 | loss 0.1796074059046805 | acc 0.9109 | cnt 2\n",
      "epoch 82 | loss 0.18191310096532107 | acc 0.892875 | cnt 3\n",
      "epoch 83 | loss 0.1824096533097327 | acc 0.902975 | cnt 4\n",
      "epoch 84 | loss 0.17025093922391535 | acc 0.92075 | cnt 5\n",
      "epoch 85 | loss 0.17792243404313923 | acc 0.92225 | cnt 0\n",
      "epoch 86 | loss 0.17037167398259043 | acc 0.921625 | cnt 1\n",
      "epoch 87 | loss 0.1689917055517435 | acc 0.91865 | cnt 2\n",
      "epoch 88 | loss 0.17159777322784067 | acc 0.90625 | cnt 3\n",
      "epoch 89 | loss 0.15737376328557728 | acc 0.91225 | cnt 4\n",
      "epoch 90 | loss 0.16122903861105442 | acc 0.91335 | cnt 5\n",
      "epoch 91 | loss 0.16055031768977643 | acc 0.9256 | cnt 0\n",
      "epoch 92 | loss 0.15718192366883157 | acc 0.917325 | cnt 1\n",
      "epoch 93 | loss 0.15748416516929864 | acc 0.91935 | cnt 2\n",
      "epoch 94 | loss 0.1464091585204005 | acc 0.930125 | cnt 0\n",
      "epoch 95 | loss 0.14487997710704803 | acc 0.915975 | cnt 1\n",
      "epoch 96 | loss 0.16532804064452647 | acc 0.930875 | cnt 0\n",
      "epoch 97 | loss 0.13255488822236658 | acc 0.93475 | cnt 0\n",
      "epoch 98 | loss 0.14736886151134967 | acc 0.928725 | cnt 1\n",
      "epoch 99 | loss 0.14129315288737415 | acc 0.924425 | cnt 2\n",
      "epoch 100 | loss 0.14129186684265732 | acc 0.931125 | cnt 3\n"
     ]
    }
   ],
   "source": [
    "#AI 만들기\n",
    "# x,t 입력은 데이터로더에서 완료\n",
    "\n",
    "F = NN(embedding_tensor).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(F.parameters(), lr = 0.015)\n",
    "epoch = 100\n",
    "prev_acc = 0\n",
    "acc_cnt = 0\n",
    "\n",
    "for e in range(epoch) :\n",
    "    F.train() #드롭아웃 활성화\n",
    "    loss_sum = 0\n",
    "    for x, t in train_dataloader :\n",
    "# y = F(x)\n",
    "        y = F(x, t)\n",
    "# y, t 비교\n",
    "        loss = loss_function(y.reshape(-1, y.shape[-1]), t.reshape(-1)) #cross entropy loss 계산 위해서 3차원을 2차원으로\n",
    "        loss_sum += loss.item()\n",
    "# F(x) 수정\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    loss_sum /= len(train_dataloader)\n",
    "# 중간 acc 점검, earlystopper 구현\n",
    "    F.eval() #드롭아웃 꺼주기\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, t in test_dataloader :\n",
    "        y = F(x, None) #성능 평가기 때문에 t 입력 안함\n",
    "        correct += (y.argmax(dim = -1) == t).sum().item()\n",
    "        total += len(x) * 4\n",
    "    acc = correct / total\n",
    "\n",
    "    if acc <= prev_acc :\n",
    "        acc_cnt += 1\n",
    "    else :\n",
    "        acc_cnt = 0\n",
    "        prev_acc = acc\n",
    "        torch.save(F, \"add_ai.pt\") #신경망 중간저장\n",
    "    print(f\"epoch {e+1} | loss {loss_sum} | acc {acc} | cnt {acc_cnt}\")\n",
    "    if acc_cnt >= 5:\n",
    "        print(\"train stopped\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "403b22ad-2013-44e5-9de4-d09db71d0b62",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1748693542566,
     "user": {
      "displayName": "Yong-Jun Jang",
      "userId": "12216012798125380557"
     },
     "user_tz": -540
    },
    "id": "403b22ad-2013-44e5-9de4-d09db71d0b62"
   },
   "outputs": [],
   "source": [
    "#신경망을 CPU로 저장해야 하기 때문에 다시 불러와서 CPU로 재저장\n",
    "\n",
    "F = torch.load(\"add_ai.pt\", weights_only=False, map_location='cpu')\n",
    "torch.save(F, \"add_ai.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
