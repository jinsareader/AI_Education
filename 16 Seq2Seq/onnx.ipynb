{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c21e7dd-4cf3-4811-85a1-0d979ebc9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx전환을 합시다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d33679-6458-48cf-bad7-0be54ed8a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 module 임포트\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71942b5f-2e94-499c-9341-67867a7db64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 커스텀 class 선언\n",
    "\n",
    "# 함수들 만들기\n",
    "class Encoder(nn.Module) :\n",
    "    def __init__(self, embedding_vector) :\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_vector, freeze = True, padding_idx = 0) # 라벨값을 벡터로 바꾸는 Embedding 함수\n",
    "        self.rnn = nn.LSTM(embedding_vector.shape[1], embedding_vector.shape[1], batch_first = True, bidirectional = True) #임베딩 열 크기를 받아서 임베딩 열 크기를 출력\n",
    "    def forward(self, x) :\n",
    "        x = self.embedding(x)\n",
    "        y, hc = self.rnn(x)\n",
    "        return y, hc\n",
    "\n",
    "class Decoder(nn.Module) :\n",
    "    def __init__(self, embedding_vector) :\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_vector, freeze = True, padding_idx = 0)\n",
    "        self.rnn = nn.LSTM(embedding_vector.shape[1] * 3, embedding_vector.shape[1], batch_first = True, bidirectional = True)\n",
    "        self.f = nn.Linear(embedding_vector.shape[1] * 4, embedding_vector.shape[0]) #RNN을 계산하고 난 뒤 벡터값을 다시 라벨값으로 바꾸는 용도, 단어 출력 용도\n",
    "        self.encoder_h_context = None #encoder_h 가공값 저장할 변수\n",
    "    def forward(self, encoder_output, encoder_hc, t = None) : #문장 여러개 처리하기 위해서 encoder_output.shape가 필요함\n",
    "        #decoder 학습 방법 2가지 (greedy, teaching_force)\n",
    "        #encoder_h 가공\n",
    "        encoder_h_forward = encoder_hc[0][0:1,:,:]\n",
    "        encoder_h_backward = encoder_hc[0][1:2,:,:] #encoder의 h값 반으로 쪼개기\n",
    "        self.encoder_h_context = torch.concat([encoder_h_forward, encoder_h_backward], dim = -1).transpose(0,1) #peeky algorithm, 적용하기 위한 변수\n",
    "        \n",
    "        batch_size = encoder_output.shape[0] #문장 갯수 정하기 = encoder에서 처리한 문장 갯수\n",
    "        decoder_input = torch.zeros(batch_size, 1).type(torch.long).to(encoder_output.device) #처음 넣는 단어 (0번째 단어인 padding)\n",
    "        decoder_hc = encoder_hc\n",
    "        decoder_output_list = [] #단어들 모아서 문장으로 만들어 출력\n",
    "\n",
    "        for i in range(4) : #t의 문자갯수만큼 반복\n",
    "            decoder_output, decoder_hc = self.forward_cal(decoder_input, decoder_hc)\n",
    "            decoder_output_list.append(decoder_output)\n",
    "\n",
    "            if t is None : #greedy (t가 없음)\n",
    "                decoder_input = decoder_output.argmax(dim = -1).detach()\n",
    "            else : #teaching-force (t가 있음)\n",
    "                decoder_input = t[:, i:i+1]\n",
    "\n",
    "        decoder_output_list = torch.cat(decoder_output_list, dim = 1) #for 문 종료 후 list로 모아놓은 tensor들을 tensor로 합치는 작업\n",
    "        return decoder_output_list, decoder_hc, None\n",
    "        \n",
    "    def forward_cal(self, x, h) : #실제 신경망 계산 함수\n",
    "        x = self.embedding(x) #라벨을 벡터로\n",
    "        x = torch.concat([self.encoder_h_context, x], dim = -1) #peeky algorithm 적용\n",
    "        output, h = self.rnn(x, h) #처음 h값을 지정하고 싶으면 x 뒤에 h값 입력하세요\n",
    "        output = torch.concat([self.encoder_h_context, output], dim = -1) #peeky algorithm 적용\n",
    "        output = self.f(output) #벡터 계산값을 다시 라벨값으로 변환\n",
    "        return output, h\n",
    "\n",
    "class NN(nn.Module) :\n",
    "    def __init__(self, embedding_vector) :\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(embedding_vector)\n",
    "        self.decoder = Decoder(embedding_vector)\n",
    "\n",
    "    def forward(self, x, t = None) :\n",
    "        y, hc = self.encoder(x)\n",
    "        y, _, _ = self.decoder(y, hc, t)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4e7b32-e3f0-499a-812b-0b22469b27b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(12, 11, padding_idx=0)\n",
      "    (rnn): LSTM(11, 11, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(12, 11, padding_idx=0)\n",
      "    (rnn): LSTM(33, 11, batch_first=True, bidirectional=True)\n",
      "    (f): Linear(in_features=44, out_features=12, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 신경망 불러오기\n",
    "\n",
    "torch_F = torch.load(\"add_ai.pt\", weights_only=False).to(\"cpu\")\n",
    "torch_F.eval()\n",
    "print(torch_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d875018-93e0-47b9-be7b-6bf1e0316a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4277: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# encoder를 onnx로 변환\n",
    "x = torch.randint(0,12, size = (1,7)).type(torch.long)\n",
    "dynamic_axes = {'input' : {0 : 'b'}, 'output' : {0 : 'b'}}\n",
    "\n",
    "torch.onnx.export(\n",
    "    torch_F, #변환할 신경망\n",
    "    x, #torch 신경망에 넣을 파리미터\n",
    "    \"add_ai.onnx\", #저장할 파일 이름\n",
    "    export_params = True, \n",
    "    opset_version = 10, #onnx 버전\n",
    "    do_constant_folding = True,\n",
    "    input_names = [\"input\"],\n",
    "    output_names = [\"output\"],\n",
    "    dynamic_axes = dynamic_axes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dccba35-c619-44a1-9244-04b6822ecb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘 변환되었는지 확인\n",
    "onnx_encoder = onnx.load(\"add_ai.onnx\")\n",
    "onnx.checker.check_model(onnx_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e67cb47-8ae7-497d-be38-3a97acbb2c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-37.882786   -2.4349308  -4.6686225 -18.059711  -17.61088\n",
      "    -9.550879    8.047626   23.350819   31.434675   30.760828\n",
      "   -46.08489    -7.0632167]\n",
      "  [-34.5723    -18.158762   -4.487035   -6.8067846 -15.768299\n",
      "   -25.196405  -15.717453    3.2757173  25.46129    45.680687\n",
      "   -47.908478  -15.194429 ]\n",
      "  [-13.131937   23.739403   16.241644    3.7718143 -12.948129\n",
      "   -28.413633  -31.463524  -21.183231   -6.0235314  10.071641\n",
      "    24.47707   -19.353819 ]\n",
      "  [ 31.420956    9.98657     5.930812   -3.5085182 -19.001299\n",
      "   -33.553288  -29.617643  -11.062666   12.912622   36.129547\n",
      "    10.258417  -15.391964 ]]]\n",
      "[[[-37.882786   -2.4349403  -4.6686273 -18.059715  -17.610886\n",
      "    -9.550886    8.047623   23.350822   31.43469    30.760847\n",
      "   -46.084896   -7.063217 ]\n",
      "  [-34.57231   -18.158766   -4.4870296  -6.806773  -15.768294\n",
      "   -25.1964    -15.717451    3.2757168  25.461287   45.68068\n",
      "   -47.9085    -15.19443  ]\n",
      "  [-13.131943   23.739407   16.241642    3.7718096 -12.948138\n",
      "   -28.41364   -31.463526  -21.183226   -6.0235243  10.0716505\n",
      "    24.477085  -19.353819 ]\n",
      "  [ 31.420965    9.986605    5.9308357  -3.5085044 -19.001305\n",
      "   -33.553307  -29.617674  -11.062689   12.912612   36.129555\n",
      "    10.25845   -15.391966 ]]]\n"
     ]
    }
   ],
   "source": [
    "# torch 신경망과 비교\n",
    "\n",
    "np_x = x.numpy().astype(np.int64)\n",
    "\n",
    "onnx_F = onnxruntime.InferenceSession(\"add_ai.onnx\", providers =  [\"CPUExecutionProvider\"])\n",
    "\n",
    "onnx_input = {onnx_F.get_inputs()[0].name : np_x}\n",
    "onnx_output = onnx_F.run(None, onnx_input)\n",
    "\n",
    "# print(\"output : \", onnx_output[0])\n",
    "# print(\"h : \", onnx_output[1])\n",
    "# print(\"c : \", onnx_output[2])\n",
    "\n",
    "y = torch_F(x)\n",
    "\n",
    "np.testing.assert_allclose(y.detach().numpy(), onnx_output[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(y.detach().numpy())\n",
    "print(onnx_output[0])\n",
    "\n",
    "#오류 메세지가 안뜨면 오차범위 내에서 변환이 잘 이루어 진 것입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fd08f-0cdf-4042-992a-8c45d3d348ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
