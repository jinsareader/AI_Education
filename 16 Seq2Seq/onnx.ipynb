{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c21e7dd-4cf3-4811-85a1-0d979ebc9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx전환을 할텐데\n",
    "# 많이 복잡합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d33679-6458-48cf-bad7-0be54ed8a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 module 임포트\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71942b5f-2e94-499c-9341-67867a7db64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 커스텀 class 선언\n",
    "\n",
    "# 함수들 만들기\n",
    "class Encoder(nn.Module) :\n",
    "    def __init__(self, embedding_vector) :\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_vector, freeze = True, padding_idx = 0) # 라벨값을 벡터로 바꾸는 Embedding 함수\n",
    "        self.rnn = nn.LSTM(embedding_vector.shape[1], embedding_vector.shape[1], batch_first = True, bidirectional = True) #임베딩 열 크기를 받아서 임베딩 열 크기를 출력\n",
    "    def forward(self, x) :\n",
    "        x = self.embedding(x)\n",
    "        y, hc = self.rnn(x)\n",
    "        return y, hc\n",
    "\n",
    "class Decoder(nn.Module) :\n",
    "    def __init__(self, embedding_vector) :\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_vector, freeze = True, padding_idx = 0)\n",
    "        self.rnn = nn.LSTM(embedding_vector.shape[1] * 3, embedding_vector.shape[1], batch_first = True, bidirectional = True)\n",
    "        self.f = nn.Linear(embedding_vector.shape[1] * 4, embedding_vector.shape[0]) #RNN을 계산하고 난 뒤 벡터값을 다시 라벨값으로 바꾸는 용도, 단어 출력 용도\n",
    "        self.encoder_h_context = None #encoder_h 가공값 저장할 변수\n",
    "    def forward(self, encoder_output, encoder_hc, t = None) : #문장 여러개 처리하기 위해서 encoder_output.shape가 필요함\n",
    "        #decoder 학습 방법 2가지 (greedy, teaching_force)\n",
    "        #encoder_h 가공\n",
    "        encoder_h_forward = encoder_hc[0][0:1,:,:]\n",
    "        encoder_h_backward = encoder_hc[0][1:2,:,:] #encoder의 h값 반으로 쪼개기\n",
    "        self.encoder_h_context = torch.concat([encoder_h_forward, encoder_h_backward], dim = -1).transpose(0,1)\n",
    "        \n",
    "        batch_size = encoder_output.shape[0] #문장 갯수 정하기 = encoder에서 처리한 문장 갯수\n",
    "        decoder_input = torch.zeros(batch_size, 1).type(torch.long).to(encoder_output.device) #처음 넣는 단어 (0번째 단어인 padding)\n",
    "        decoder_hc = encoder_hc\n",
    "        decoder_output_list = [] #단어들 모아서 문장으로 만들어 출력\n",
    "\n",
    "        for i in range(4) : #t의 문자갯수만큼 반복\n",
    "            decoder_output, decoder_hc = self.forward_cal(decoder_input, decoder_hc)\n",
    "            decoder_output_list.append(decoder_output)\n",
    "\n",
    "            if t is None : #greedy (t가 없음)\n",
    "                decoder_input = decoder_output.argmax(dim = -1).detach()\n",
    "            else : #teaching-force (t가 있음)\n",
    "                decoder_input = t[:, i:i+1]\n",
    "\n",
    "        decoder_output_list = torch.cat(decoder_output_list, dim = 1) #for 문 종료 후 list로 모아놓은 tensor들을 tensor로 합치는 작업\n",
    "        return decoder_output_list, decoder_hc, None\n",
    "        \n",
    "    def forward_cal(self, x, h) : #실제 신경망 계산 함수\n",
    "        x = self.embedding(x) #라벨을 벡터로\n",
    "        x = torch.concat([self.encoder_h_context, x], dim = -1)\n",
    "        output, h = self.rnn(x, h) #처음 h값을 지정하고 싶으면 x 뒤에 h값 입력하세요\n",
    "        output = torch.concat([self.encoder_h_context, output], dim = -1)\n",
    "        output = self.f(output) #벡터 계산값을 다시 라벨값으로 변환\n",
    "        return output, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4e7b32-e3f0-499a-812b-0b22469b27b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(12, 11, padding_idx=0)\n",
      "  (rnn): LSTM(11, 11, batch_first=True, bidirectional=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# encoder부터 전환작업\n",
    "# encoder 신경망 불러오기\n",
    "\n",
    "torch_encoder = torch.load(\"num_encoder.pt\", weights_only=False).to(\"cpu\")\n",
    "torch_encoder.eval()\n",
    "print(torch_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d875018-93e0-47b9-be7b-6bf1e0316a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4244: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# encoder를 onnx로 변환\n",
    "x = torch.randint(0,12, size = (1,7)).type(torch.long)\n",
    "dynamic_axes = {'input' : {0 : 'b'}, 'output' : {0 : 'b'}, \"h\" : {1 : 'b'}, \"c\" : {1 : 'b'}}\n",
    "\n",
    "torch.onnx.export(\n",
    "    torch_encoder, #변환할 신경망\n",
    "    x, #torch 신경망에 넣을 파리미터\n",
    "    \"num_encoder.onnx\", #저장할 파일 이름\n",
    "    export_params = True, \n",
    "    opset_version = 10, #onnx 버전\n",
    "    do_constant_folding = True,\n",
    "    input_names = [\"input\"],\n",
    "    output_names = [\"output\", \"h\", \"c\"],\n",
    "    dynamic_axes = dynamic_axes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dccba35-c619-44a1-9244-04b6822ecb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘 변환되었는지 확인\n",
    "onnx_encoder = onnx.load(\"num_encoder.onnx\")\n",
    "onnx.checker.check_model(onnx_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e67cb47-8ae7-497d-be38-3a97acbb2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch 신경망과 비교\n",
    "\n",
    "np_x = x.numpy().astype(np.int64)\n",
    "\n",
    "onnx_encoder = onnxruntime.InferenceSession(\"num_encoder.onnx\", providers =  [\"CPUExecutionProvider\"])\n",
    "\n",
    "onnx_input = {onnx_encoder.get_inputs()[0].name : np_x}\n",
    "onnx_output = onnx_encoder.run(None, onnx_input)\n",
    "\n",
    "# print(\"output : \", onnx_output[0])\n",
    "# print(\"h : \", onnx_output[1])\n",
    "# print(\"c : \", onnx_output[2])\n",
    "\n",
    "y, hc = torch_encoder(x)\n",
    "\n",
    "np.testing.assert_allclose(y.detach().numpy(), onnx_output[0], rtol=1e-03, atol=1e-05)\n",
    "np.testing.assert_allclose(hc[0].detach().numpy(), onnx_output[1], rtol=1e-03, atol=1e-05)\n",
    "np.testing.assert_allclose(hc[1].detach().numpy(), onnx_output[2], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "#오류 메세지가 안뜨면 오차범위 내에서 변환이 잘 이루어 진 것입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fd08f-0cdf-4042-992a-8c45d3d348ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64817977-8268-4efe-a83b-77e8ae1245bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (embedding): Embedding(12, 11, padding_idx=0)\n",
      "  (rnn): LSTM(33, 11, batch_first=True, bidirectional=True)\n",
      "  (f): Linear(in_features=44, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#decoder 변환작업\n",
    "\n",
    "torch_decoder = torch.load(\"num_decoder.pt\", weights_only=False).to(\"cpu\")\n",
    "torch_decoder.eval()\n",
    "\n",
    "print(torch_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a486199c-7d10-4aa3-bc89-0a938a8ab214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder를 onnx로 변환\n",
    "encoder_output = torch.randn(1,7,22)\n",
    "encoder_h = torch.randn(2,1,11)\n",
    "encoder_c = torch.randn(2,1,11)\n",
    "dynamic_axes = {\"encoder_output\" : {0 : 'b'}, \"encoder_h\" : {1 : 'b'}, \"encoder_c\" : {1 : 'b'}, \"output\" : {0 : 'b'}, \"h\" : {1 : 'b'}, \"c\" : {1 : 'b'}}\n",
    "\n",
    "torch.onnx.export(\n",
    "    torch_decoder, #변환할 신경망\n",
    "    (encoder_output, (encoder_h, encoder_c), None), #torch 신경망의 파라미터\n",
    "    \"num_decoder.onnx\", #저장 파일 이름\n",
    "    export_params = True, #w, b값 저장할지\n",
    "    opset_version = 10, #onnx 버전\n",
    "    do_constant_folding = True,\n",
    "    input_names = [\"encoder_output\",\"encoder_h\",\"encoder_c\"],\n",
    "    output_names = [\"output\", \"h\", \"c\"],\n",
    "    dynamic_axes = dynamic_axes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "723eb70d-84bf-4c30-904a-1f527ca60733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onnx로 변환이 잘 되었는지 확인\n",
    "onnx_decoder = onnx.load(\"num_decoder.onnx\")\n",
    "onnx.checker.check_model(onnx_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59df3cda-1d73-42b0-ae78-cdd79d412de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch와 비교\n",
    "np_encoder_output = encoder_output.numpy().astype(np.float32)\n",
    "np_encoder_h = encoder_h.numpy().astype(np.float32)\n",
    "np_encoder_c = encoder_c.numpy().astype(np.float32)\n",
    "\n",
    "onnx_decoder = onnxruntime.InferenceSession(\"num_decoder.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "inputs_names = onnx_decoder.get_inputs()\n",
    "onnx_input = {inputs_names[0].name : np_encoder_output, inputs_names[1].name : np_encoder_h, inputs_names[2].name : np_encoder_c}\n",
    "onnx_output = onnx_decoder.run(None, onnx_input)\n",
    "\n",
    "y, hc, _ = torch_decoder(encoder_output, (encoder_h, encoder_c))\n",
    "\n",
    "np.testing.assert_allclose(y.detach().numpy(), onnx_output[0], rtol=1e-03, atol=1e-05)\n",
    "np.testing.assert_allclose(hc[0].detach().numpy(), onnx_output[1], rtol=1e-03, atol=1e-05)\n",
    "np.testing.assert_allclose(hc[1].detach().numpy(), onnx_output[2], rtol=1e-03, atol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185eb79b-2801-42d7-a48c-0459f8a602dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
