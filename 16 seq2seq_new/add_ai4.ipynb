{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e79d4a3-f6f0-4dcd-89fa-423105abc950",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data 전처리\n",
    "## 숫자 벡터 사전 만들기 \n",
    "## 데이터 불러오기\n",
    "## 데이터 x t로 나누기\n",
    "## 데이터 라벨링=정수로 바꾸기(신경망 안에 벡터 사전이 있을 때) or 벡터화=1차원 배열(신경망 안에 벡터 사진이 없을 때)\n",
    "### 참고로 우리는 아직 <sos>와 <eos>를 쓰지 않을 겁니다.\n",
    "\n",
    "# AI 만들기\n",
    "## AI 학습\n",
    "### DataLoader에 싣기 (x, t 입력)\n",
    "### Encoder와 Decoder 구현 하기 (함수 만들기)\n",
    "### y = F(x) (순전파)\n",
    "### 손실함수\n",
    "### 역전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed06b3b-e8d2-4f40-be6d-e6768a3c271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 import\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"\"), \"..\"))\n",
    "import custom\n",
    "import numpy as np\n",
    "\n",
    "# Data 전처리 모듈 : custom과 numpy만으로 가능함\n",
    "from tqdm import tqdm #자료가 많으니 진행상황은 봅시다\n",
    "\n",
    "# AI 만들기 모듈\n",
    "import torch\n",
    "import torch.nn as nn #클래스 형식의 신경망 함수\n",
    "import torch.nn.functional as F #함수 형식의 신경망 함수\n",
    "from torch.utils.data import DataLoader #데이터 batch 나눠주는 역할의 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b374ef61-4566-42a8-bfa1-597ddcb85d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "(12, 11)\n",
      "{' ': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '0': 10, '+': 11}\n"
     ]
    }
   ],
   "source": [
    "## 숫자 벡터 사전 만들기\n",
    "## ' ',1,2,3,4,5,6,7,8,9,0,+ : 12개\n",
    "## ' '(pad 문자) 는 0행렬\n",
    "## 나머지 11개는 원 핫 인코딩\n",
    "\n",
    "#벡터 값 만들기\n",
    "vector_list = np.zeros((1,11)) # np.array의 백터 값 저장할 pad값만 저장된 행렬\n",
    "vector_list = np.append(vector_list, np.eye(11), axis = 0) # 대각선 값은 1이고 나머지는 0인 정사각 행렬\n",
    "print(vector_list)\n",
    "print(vector_list.shape)\n",
    "\n",
    "#숫자-라벨링 사전\n",
    "num_dict = {}\n",
    "num_dict[' '] = 0\n",
    "\n",
    "for i in range(1,10) : #1~9까지 반복문으로 넣기\n",
    "    num_dict[str(i)] = i\n",
    "num_dict['0'] = 10\n",
    "num_dict['+'] = 11\n",
    "print(num_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29dd6a5a-058b-4305-b208-efc3cb2fd7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "18+8   _26  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 데이터 불러오기\n",
    "file_name = 'addition.txt'\n",
    "with open(file_name, mode = \"r\") as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "print(len(data))\n",
    "print(data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "244718da-56d7-4bfa-b0f6-6de4d45eb3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 갯수 : 50000\n",
      "t의 갯수 : 50000\n",
      "10번째 x : 18+8   \n",
      "10번째 t : 26  \n",
      "10번째 x 길이 : 7\n",
      "10번째 t 길이 : 4\n"
     ]
    }
   ],
   "source": [
    "## 데이터 x, t로 나누기\n",
    "data_x = []\n",
    "data_t = []\n",
    "\n",
    "for d in data :\n",
    "    d = d.split(\"_\")\n",
    "    data_x.append(d[0])\n",
    "    data_t.append(d[1].replace('\\n','')) #개행문자 제거\n",
    "\n",
    "print(\"x의 갯수 :\",len(data_x))\n",
    "print(\"t의 갯수 :\",len(data_t))\n",
    "print(\"10번째 x :\",data_x[10])\n",
    "print(\"10번째 t :\",data_t[10])\n",
    "print(\"10번째 x 길이 :\",len(data_x[10]))\n",
    "print(\"10번째 t 길이 :\",len(data_t[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33e9a3d9-7065-44d2-b943-a7015f121c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 7)\n",
      "(50000, 4)\n"
     ]
    }
   ],
   "source": [
    "## 데이터 라벨링=정수로 바꾸기(신경망 안에 벡터 사전이 있을 때) or 벡터화=1차원 배열(신경망 안에 벡터 사진이 없을 때)\n",
    "## 라벨링 하겠습니다 (= 신경망 안에 벡터 list 넣겠습니다)\n",
    "\n",
    "for i in range(len(data_x)) :\n",
    "    temp = data_x[i]\n",
    "    temp = list(temp) #문장을 문자 하나하나씩 끊어서 list화 #역산 하려면 \"\".join() 쓰면 됩니다\n",
    "    vector = custom.word_vectorize(temp, num_dict, 7)\n",
    "    data_x[i] = vector\n",
    "data_x = np.array(data_x)\n",
    "\n",
    "for i in range(len(data_t)) :\n",
    "    temp = data_t[i]\n",
    "    temp = list(temp)\n",
    "    vector = custom.word_vectorize(temp, num_dict, 4)\n",
    "    data_t[i] = vector\n",
    "data_t = np.array(data_t)\n",
    "\n",
    "print(data_x.shape)\n",
    "print(data_t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45efbc64-1232-41e0-bac8-f18ae3f160c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "## AI 학습\n",
    "### DataLoader에 싣기 (x, t 입력)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tensor_x = torch.tensor(data_x, dtype = torch.long, device = device)\n",
    "tensor_t = torch.tensor(data_t, dtype = torch.long, device = device)\n",
    "\n",
    "### 앞의 40000번째 까지는 train, 뒤의 10000개는 test(val)\n",
    "s = 40000\n",
    "train_zip = list(zip(tensor_x[:s], tensor_t[:s])) \n",
    "test_zip = list(zip(tensor_x[s:], tensor_t[s:]))\n",
    "\n",
    "train_dataloader = DataLoader(train_zip, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(test_zip, batch_size=1000, shuffle=False)\n",
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea636c0e-8cf4-4f5f-9c6f-1515f670b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encoder와 Decoder 구현 하기 (함수 만들기)\n",
    "\n",
    "from add_ai4 import Encoder\n",
    "from add_ai4 import Decoder\n",
    "from add_ai4 import Encoder_n_Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b67dfe3-14c5-4759-bbc2-130cc55c3865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | loss 1.6618297919631004 | acc 0.45695 | cnt 0\n",
      "epoch 2 | loss 1.272785905599594 | acc 0.51935 | cnt 0\n",
      "epoch 3 | loss 1.1100012508034707 | acc 0.5611 | cnt 0\n",
      "epoch 4 | loss 0.9953242787718772 | acc 0.59915 | cnt 0\n",
      "epoch 5 | loss 0.9196522678434849 | acc 0.638875 | cnt 0\n",
      "epoch 6 | loss 0.883374175131321 | acc 0.648675 | cnt 0\n",
      "epoch 7 | loss 0.8535747571289539 | acc 0.658675 | cnt 0\n",
      "epoch 8 | loss 0.8258294619619846 | acc 0.6709 | cnt 0\n",
      "epoch 9 | loss 0.8026901532709598 | acc 0.67405 | cnt 0\n",
      "epoch 10 | loss 0.7963377472758293 | acc 0.68455 | cnt 0\n",
      "epoch 11 | loss 0.785775791555643 | acc 0.67725 | cnt 1\n",
      "epoch 12 | loss 0.7736407127976418 | acc 0.698675 | cnt 0\n",
      "epoch 13 | loss 0.7604573395848274 | acc 0.700925 | cnt 0\n",
      "epoch 14 | loss 0.753163028806448 | acc 0.696425 | cnt 1\n",
      "epoch 15 | loss 0.7430438241362571 | acc 0.694125 | cnt 2\n",
      "epoch 16 | loss 0.7388485977053643 | acc 0.709475 | cnt 0\n",
      "epoch 17 | loss 0.709599269926548 | acc 0.717675 | cnt 0\n",
      "epoch 18 | loss 0.6684644888341427 | acc 0.7413 | cnt 0\n",
      "epoch 19 | loss 0.576044208407402 | acc 0.770675 | cnt 0\n",
      "epoch 20 | loss 0.4720406251400709 | acc 0.8138 | cnt 0\n",
      "epoch 21 | loss 0.41534706234931945 | acc 0.847275 | cnt 0\n",
      "epoch 22 | loss 0.36689723081886766 | acc 0.860075 | cnt 0\n",
      "epoch 23 | loss 0.33908425852656365 | acc 0.8693 | cnt 0\n",
      "epoch 24 | loss 0.3126586893573403 | acc 0.89185 | cnt 0\n",
      "epoch 25 | loss 0.2879907303676009 | acc 0.89385 | cnt 0\n",
      "epoch 26 | loss 0.2600879920646548 | acc 0.8949 | cnt 0\n",
      "epoch 27 | loss 0.24249825771898031 | acc 0.92135 | cnt 0\n",
      "epoch 28 | loss 0.22582591507583857 | acc 0.92405 | cnt 0\n",
      "epoch 29 | loss 0.2195213583856821 | acc 0.923625 | cnt 1\n",
      "epoch 30 | loss 0.18954401560127734 | acc 0.934625 | cnt 0\n",
      "epoch 31 | loss 0.18551075691357255 | acc 0.93525 | cnt 0\n",
      "epoch 32 | loss 0.18090310962870718 | acc 0.952325 | cnt 0\n",
      "epoch 33 | loss 0.15165434043854475 | acc 0.9599 | cnt 0\n",
      "epoch 34 | loss 0.14750308990478517 | acc 0.94995 | cnt 1\n",
      "epoch 35 | loss 0.16656268840655686 | acc 0.94655 | cnt 2\n",
      "epoch 36 | loss 0.1377548234164715 | acc 0.960425 | cnt 0\n",
      "epoch 37 | loss 0.14186078609898686 | acc 0.917975 | cnt 1\n",
      "epoch 38 | loss 0.13644360519945622 | acc 0.9628 | cnt 0\n",
      "epoch 39 | loss 0.12338239777833224 | acc 0.963725 | cnt 0\n",
      "epoch 40 | loss 0.12200177365913988 | acc 0.94415 | cnt 1\n",
      "epoch 41 | loss 0.14502337025478482 | acc 0.96305 | cnt 2\n",
      "epoch 42 | loss 0.10529503806494177 | acc 0.96365 | cnt 3\n",
      "epoch 43 | loss 0.128765154145658 | acc 0.970575 | cnt 0\n",
      "epoch 44 | loss 0.10930320953950286 | acc 0.96925 | cnt 1\n",
      "epoch 45 | loss 0.09989297355525195 | acc 0.9698 | cnt 2\n",
      "epoch 46 | loss 0.12421919327229261 | acc 0.961 | cnt 3\n",
      "epoch 47 | loss 0.10531568282283843 | acc 0.9725 | cnt 0\n",
      "epoch 48 | loss 0.09525870804674924 | acc 0.96465 | cnt 1\n",
      "epoch 49 | loss 0.10081504145637155 | acc 0.973775 | cnt 0\n",
      "epoch 50 | loss 0.11263688414357603 | acc 0.96395 | cnt 1\n",
      "epoch 51 | loss 0.1152778376918286 | acc 0.962525 | cnt 2\n",
      "epoch 52 | loss 0.08776000143028796 | acc 0.97585 | cnt 0\n",
      "epoch 53 | loss 0.08223002408631146 | acc 0.978925 | cnt 0\n",
      "epoch 54 | loss 0.11959577550180256 | acc 0.976725 | cnt 1\n",
      "epoch 55 | loss 0.07456787960603833 | acc 0.9735 | cnt 2\n",
      "epoch 56 | loss 0.07373704222030937 | acc 0.979625 | cnt 0\n",
      "epoch 57 | loss 0.14506491216830908 | acc 0.97595 | cnt 1\n",
      "epoch 58 | loss 0.07289360103197395 | acc 0.978775 | cnt 2\n",
      "epoch 59 | loss 0.08534734488464892 | acc 0.969325 | cnt 3\n",
      "epoch 60 | loss 0.09379366958513856 | acc 0.9803 | cnt 0\n",
      "epoch 61 | loss 0.0783648718520999 | acc 0.9683 | cnt 1\n",
      "epoch 62 | loss 0.07357673342339695 | acc 0.976475 | cnt 2\n",
      "epoch 63 | loss 0.08522950643207877 | acc 0.9707 | cnt 3\n",
      "epoch 64 | loss 0.0923033195734024 | acc 0.97875 | cnt 4\n",
      "epoch 65 | loss 0.06647274709772319 | acc 0.98065 | cnt 0\n",
      "epoch 66 | loss 0.09712132952176035 | acc 0.9696 | cnt 1\n",
      "epoch 67 | loss 0.07141721427906304 | acc 0.983025 | cnt 0\n",
      "epoch 68 | loss 0.08741284884046763 | acc 0.971 | cnt 1\n",
      "epoch 69 | loss 0.0791662044916302 | acc 0.982625 | cnt 2\n",
      "epoch 70 | loss 0.057871270910836756 | acc 0.98525 | cnt 0\n",
      "epoch 71 | loss 0.0833922717999667 | acc 0.961125 | cnt 1\n",
      "epoch 72 | loss 0.07938051079865545 | acc 0.97855 | cnt 2\n",
      "epoch 73 | loss 0.060075972573831675 | acc 0.98275 | cnt 3\n",
      "epoch 74 | loss 0.07062045671977103 | acc 0.96185 | cnt 4\n",
      "epoch 75 | loss 0.07190815398469567 | acc 0.98335 | cnt 5\n",
      "train stopped\n"
     ]
    }
   ],
   "source": [
    "encoder_file_name = 'data/encoder4.pt'\n",
    "decoder_file_name = 'data/decoder4.pt'\n",
    "\n",
    "tensor_vector = torch.tensor(vector_list, dtype = torch.float)\n",
    "encoder = Encoder(tensor_vector).to(device)\n",
    "decoder = Decoder(tensor_vector, 4).to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "encoder_optim = torch.optim.Adam(encoder.parameters(), lr = 0.015)\n",
    "decoder_optim = torch.optim.Adam(decoder.parameters(), lr = 0.025)\n",
    "\n",
    "epoch = 100\n",
    "prev_acc = 0\n",
    "cnt = 0\n",
    "\n",
    "for e in range(epoch) :\n",
    "    loss_sum = 0\n",
    "    encoder.train() #dropout 켜주기\n",
    "    decoder.train()\n",
    "    for x, t in train_dataloader :\n",
    "### y = F(x) (순전파)\n",
    "        y, hc = encoder(x)\n",
    "        y, _, _ = decoder(y, hc)\n",
    "### 손실함수\n",
    "        loss = loss_func(y.reshape(-1, y.shape[-1]) , t.reshape(-1)) #3차원을 2차원으로 펴주기\n",
    "        loss_sum += loss.item()\n",
    "### 역전파\n",
    "        loss.backward()\n",
    "        decoder_optim.step()\n",
    "        encoder_optim.step()\n",
    "        decoder_optim.zero_grad()\n",
    "        encoder_optim.zero_grad()\n",
    "    loss_sum /= len(train_dataloader) #평균 구하기\n",
    "### 중간 점검\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    encoder.eval() #dropout 꺼주기\n",
    "    decoder.eval()\n",
    "    for x, t in test_dataloader :\n",
    "        with torch.no_grad() :\n",
    "            y, hc = encoder(x)\n",
    "            y, _, _ = decoder(y, hc)\n",
    "            correct += (y.argmax(dim = -1) == t).sum().item()\n",
    "        total += len(x) * 4\n",
    "    acc = correct / total\n",
    "### earlystopper\n",
    "    if acc <= prev_acc :\n",
    "        cnt += 1\n",
    "    else :\n",
    "        cnt = 0\n",
    "        prev_acc = acc\n",
    "        torch.save(encoder, encoder_file_name) #중간 저장\n",
    "        torch.save(decoder, decoder_file_name)\n",
    "    print(f\"epoch {e+1} | loss {loss_sum} | acc {acc} | cnt {cnt}\")\n",
    "    if cnt >= 5 :\n",
    "        print(\"train stopped\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ba0a399-07bb-49aa-abf4-48c626877899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder_n_Decoder(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(12, 11, padding_idx=0)\n",
      "    (rnn): LSTM(11, 11, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(12, 11, padding_idx=0)\n",
      "    (rnn): LSTM(33, 11, batch_first=True, bidirectional=True)\n",
      "    (f): Linear(in_features=44, out_features=12, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# onnx로 변환하기 쉽게 하기 위해 다시 불러와서 cpu로 변환 한 다음에 하나로 묶는 작업\n",
    "\n",
    "encoder = torch.load(encoder_file_name, weights_only=False, map_location='cpu') #cpu로 불러오기 \n",
    "decoder = torch.load(decoder_file_name, weights_only=False, map_location='cpu')\n",
    "\n",
    "F = Encoder_n_Decoder(encoder, decoder)\n",
    "print(F)\n",
    "print(F.state_dict()['encoder.embedding.weight']) #.state_dict() : 신경망 내의 W, b 값 불러오는 함수\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d1727c-3dad-4901-ad9f-02f21de551c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 묶은 신경망을 다시 저장\n",
    "\n",
    "torch.save(F, \"data/add_ai4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f1cce-5e92-46b1-bf09-0d04d6d31ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
