{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83b15e6-2929-46ec-a173-dfd123d4f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch 함수 불러오기\n",
    "# onnx로 변환하기\n",
    "# 변환된 onnx 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6693e4ef-52e9-4174-a587-577a5326b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# torch 함수 불러오기\n",
    "import torch\n",
    "from add_ai4 import Encoder\n",
    "from add_ai4 import Decoder\n",
    "from add_ai4 import Encoder_n_Decoder\n",
    "# onnx로 변환하기\n",
    "import torch.onnx\n",
    "# 변환된 onnx 검증하기\n",
    "import onnx # 검증만\n",
    "import onnxruntime # 실제 계산까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555f1089-8dc0-4699-9a32-ea9725a067ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder_n_Decoder(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(12, 11, padding_idx=0)\n",
      "    (rnn): LSTM(11, 11, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(12, 11, padding_idx=0)\n",
      "    (rnn): LSTM(33, 11, batch_first=True, bidirectional=True)\n",
      "    (f): Linear(in_features=44, out_features=12, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 함수 불러오기\n",
    "file_name = \"data/add_ai4\"\n",
    "\n",
    "F = torch.load(file_name + '.pt', weights_only=False, map_location='cpu') # cpu로 불러오기\n",
    "F.eval() # dropout 끄기\n",
    "\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e794154a-1278-4819-ba15-dbfd5f1280a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4277: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# onnx로 변환하기\n",
    "x = torch.randint(0, 12, (1,7)).type(torch.long) # 입력값 더미 텐서\n",
    "dynamic_axes = {'x' : {0 : 'b', 1 : 'f'}, 'y' : {0 : 'b'}} # 가변길이 차원 지정 dict\n",
    "\n",
    "torch.onnx.export(\n",
    "    F,\n",
    "    x,\n",
    "    file_name + '.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=20,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['x'],\n",
    "    output_names=['y'],\n",
    "    dynamic_axes=dynamic_axes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37263085-33bc-4e8c-b6ce-4c8c392b3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx 확인하기\n",
    "onnx_F = onnx.load(file_name + '.onnx')\n",
    "\n",
    "onnx.checker.check_model(onnx_F) #문제 없이 저장이 되었으면 오류 메세지 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a11cb8b-c834-4937-92e5-e0a4f0197121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-36.942387    31.429958     8.92841    -24.541452   -44.41225\n",
      "   -42.131138   -21.36669     12.18445     32.549828    41.06372\n",
      "    11.493965    -5.452112  ]\n",
      "  [-10.928525    24.368797     9.098663   -18.043856   -32.33855\n",
      "   -32.81287    -26.56531    -16.617216     2.483396    32.603428\n",
      "    29.365519   -16.82774   ]\n",
      "  [-10.379347    -3.0305548   -6.202652   -13.092377   -17.694893\n",
      "   -19.53572    -16.12387    -11.606823    -1.4367698   14.426321\n",
      "     6.8341856  -19.508898  ]\n",
      "  [ 33.518322   -30.90601    -36.205044   -34.891937   -17.82804\n",
      "    -0.27989483  10.262782    18.363842    23.23783     15.644077\n",
      "    -9.762018   -13.82737   ]]]\n",
      "[[[-36.9424      31.429985     8.92842    -24.541447   -44.41224\n",
      "   -42.131134   -21.366692    12.1844425   32.549812    41.06371\n",
      "    11.493982    -5.4521103 ]\n",
      "  [-10.928526    24.368793     9.098658   -18.04386    -32.33856\n",
      "   -32.812874   -26.56531    -16.61721      2.4834046   32.603428\n",
      "    29.365517   -16.82774   ]\n",
      "  [-10.379359    -3.0305667   -6.2026567  -13.092377   -17.69489\n",
      "   -19.535717   -16.123865   -11.606821    -1.4367672   14.426318\n",
      "     6.834174   -19.508902  ]\n",
      "  [ 33.51831    -30.90601    -36.205044   -34.89194    -17.828047\n",
      "    -0.27989554  10.262781    18.363842    23.237831    15.644076\n",
      "    -9.762019   -13.827372  ]]]\n"
     ]
    }
   ],
   "source": [
    "# 실제 계산값 비교\n",
    "onnx_F = onnxruntime.InferenceSession(file_name + '.onnx', providers=[\"CPUExecutionProvider\"])\n",
    "np_x = x.numpy()\n",
    "\n",
    "y = F(x) # torch 계산 값\n",
    "\n",
    "inputs = {onnx_F.get_inputs()[0].name : np_x}\n",
    "outputs = onnx_F.run(None, inputs)\n",
    "onnx_y = outputs[0] # onnx 계산 값\n",
    "\n",
    "print(y.detach().numpy())\n",
    "print(onnx_y)\n",
    "\n",
    "np.testing.assert_allclose(y.detach().numpy(), onnx_y, rtol=1e-03, atol=1e-05) #계산 결과가 오차범위 내 차이 없으면 오류 메세지 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738dc8b-f8d6-4355-9d7e-3ea9e20905d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
