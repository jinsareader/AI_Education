{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fad2f20-4e9a-4224-b876-7777664297bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. x, t입력\n",
    "# x : 소리\n",
    "# 소리를 mfcc 때리면 (소리 길이, 13) 의 자료로 변환\n",
    "# t : 과일 종류 7개\n",
    "\n",
    "# 2. 함수 만들면\n",
    "# Encoder = rnn(13, 13)\n",
    "# Decoder = Linear(13, 7), decoder의 입력값은, Encoder의 마지막 값 (h)\n",
    "# 만약 Encoder가 Bidirection = True 면\n",
    "# h[0:1,:,:]\n",
    "# h[1:2,:,:] 을 concat으로 이어 붙인 후, reshape 하고 (-1, 26)\n",
    "# Decoder 입력값도 26개로 늘어남\n",
    "\n",
    "# 손실함수 : CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc4d926-fc0f-41c9-b5dc-cef7dc87ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile #소리 불러오는 모듈\n",
    "import numpy #소리 가공\n",
    "from python_speech_features import mfcc #mfcc 계산해주는 함수\n",
    "\n",
    "import torch #AI 모듈\n",
    "import torch.nn as nn\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c3895d-0244-4606-b850-52ca7a0eae38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'kiwi', 'lime', 'orange', 'peach', 'pineapple']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 자료 불러오고 전처리 작업\n",
    "\n",
    "#t 값 가져오기\n",
    "t_list = os.listdir('data/')\n",
    "remove_list = []\n",
    "\n",
    "for t in t_list :\n",
    "    if t.find('.') >= 0 :\n",
    "        remove_list.append(t) \n",
    "\n",
    "for r in remove_list :\n",
    "    t_list.remove(r)\n",
    "\n",
    "print(t_list)\n",
    "print(t_list.index('kiwi')) #해당 원소가 들어있는 위치 출력하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7861aed-6bcb-4d0a-a93d-5783935bd598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "torch.Size([1, 43, 13])\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "data = []\n",
    "\n",
    "#x값 가져오기\n",
    "for t in t_list :\n",
    "    x_list = os.listdir('data/' + t)\n",
    "    # print(x_list)\n",
    "    for x in x_list :\n",
    "        if x.find('.wav') < 0 : #예외 : .wav 파일이 아니면\n",
    "            continue\n",
    "        freq, signal = wavfile.read('data/' + t + '/' + x) # 소리 읽어오는 부분\n",
    "        x_data = mfcc(signal, freq) #numpy.array 형태의 데이터\n",
    "        # print(x_data.shape)\n",
    "        x_tensor = torch.tensor(x_data, dtype = torch.float, device = device).unsqueeze(0) #AI에서 계산하기 위해 바로 텐서로 변환, 3차원으로 만들기 위해 unsqueeze\n",
    "        t_tensor = torch.tensor(t_list.index(t), dtype = torch.long, device = device)\n",
    "        temp = (x_tensor, t_tensor) #x값과 t값을 tuple 형태로 묶음, Dataloader를 수동으로 만드는 것과 비슷함\n",
    "        data.append(temp)\n",
    "        # print(data)\n",
    "\n",
    "print(len(data))\n",
    "print(data[10][0].shape)\n",
    "\n",
    "#하나하나씩 데이터를 넣으면 padding작업이 필요없다 (padding은 길이가 다른 자료들을 한번에 계산하기위해 하는 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8875cb3-fa86-4f00-8c8f-1eede19ecf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN import Encoder\n",
    "from NN import Decoder\n",
    "from NN import Encoder_n_Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493badbe-8e5b-4fd7-826f-6d1b0e1be278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | loss 2.0441778058097477\n",
      "epoch 2 | loss 1.7387495790209089\n",
      "epoch 3 | loss 1.1542143509501503\n",
      "epoch 4 | loss 0.6046182169800713\n",
      "epoch 5 | loss 0.2637590237316631\n",
      "epoch 6 | loss 0.1059524117303746\n",
      "epoch 7 | loss 0.057401058685389306\n",
      "epoch 8 | loss 0.019258661246636794\n",
      "epoch 9 | loss 0.012682095127889799\n",
      "epoch 10 | loss 0.008900907126787518\n",
      "epoch 11 | loss 0.006524742715105059\n",
      "epoch 12 | loss 0.0049787548331854245\n",
      "epoch 13 | loss 0.003925150806372542\n",
      "epoch 14 | loss 0.003178751379961059\n",
      "epoch 15 | loss 0.002632137972839354\n",
      "epoch 16 | loss 0.0022162297283232746\n",
      "epoch 17 | loss 0.0018896977813537455\n",
      "epoch 18 | loss 0.0016284974837963958\n",
      "epoch 19 | loss 0.0014158057434196095\n",
      "epoch 20 | loss 0.0012405425210350327\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(13)\n",
    "decoder = Decoder(26)\n",
    "loss_function = nn.CrossEntropyLoss() #분류분제 (네, 아니오)\n",
    "encoder_optim = torch.optim.Adam(encoder.parameters(), lr = 0.002)\n",
    "decoder_optim = torch.optim.Adam(decoder.parameters(), lr = 0.002)\n",
    "epoch = 20\n",
    "\n",
    "for e in range(epoch) :\n",
    "    loss_sum = 0\n",
    "    encoder.train() #dropout 켜기\n",
    "    decoder.train()\n",
    "    for x, t in data :\n",
    "        y, hc = encoder(x)\n",
    "        y = decoder(hc[0])\n",
    "\n",
    "        loss = loss_function(y, t.unsqueeze(0)) #y는 2차원, t는 1차원\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        decoder_optim.step()\n",
    "        encoder_optim.step()\n",
    "        decoder_optim.zero_grad()\n",
    "        encoder_optim.zero_grad()\n",
    "    loss_sum /= len(data)\n",
    "\n",
    "    print(f\"epoch {e+1} | loss {loss_sum}\")\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "torch.save(encoder.to(\"cpu\"), 'encoder.pt')\n",
    "torch.save(decoder.to(\"cpu\"), 'decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82ce551-a807-46bd-b47a-a90929f09df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 불러와서 하나로 합치기\n",
    "encoder = torch.load('encoder.pt', weights_only=False, map_location=\"cpu\")\n",
    "decoder = torch.load('decoder.pt', weights_only=False, map_location=\"cpu\")\n",
    "\n",
    "F = Encoder_n_Decoder(encoder, decoder)\n",
    "F.eval()\n",
    "torch.save(F.to(\"cpu\"), \"sound_ai.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9aed4d0-f24f-4f66-b758-e3a0fc4a5e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "## AI 정확도 알아보기\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for x, t in data :\n",
    "    with torch.no_grad() : #자동 미분기능 끄는 함수, 안넣어도 문제는 없지만, 넣으면 살짝 더 빨라집니다.\n",
    "        y = F(x)\n",
    "    if y.argmax(dim = -1).item() == t :\n",
    "        correct += 1\n",
    "        \n",
    "acc = correct / len(data)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6d27c1-d999-46dd-9479-eb981c942458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문장갯수, 단어갯수, 벡터)\n",
    "# (소리갯수, 소리길이, 벡터)\n",
    "# (batchs, features, vector)\n",
    "# (b, f, v) # batch first는 이렇게 자료를 넣겠다는 뜻이고\n",
    "\n",
    "# (f, b, v) # batch first가 false일 경우"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
