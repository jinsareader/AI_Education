{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b315eddb-33e9-4470-9274-825d2833a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #torch 함수들 불러오는 역할\n",
    "import torch.nn as nn\n",
    "import torch.onnx #불러온 torch 함수를  onnx로 변환하는 역할\n",
    "import onnx #onnx 확인\n",
    "import onnxruntime #onnx 계산\n",
    "import numpy as np # onnx 계산 할 때는 numpy를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db426ad5-de5c-46de-951a-23b4e0b85abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 선언\n",
    "\n",
    "class NN(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.encode_rnn = nn.LSTM(13, 13, batch_first = True)\n",
    "        self.decode_f = nn.Linear(13, 7)\n",
    "        \n",
    "    def encode_forward(self, x) :\n",
    "        y, hc = self.encode_rnn(x)\n",
    "        return y, hc        \n",
    "        \n",
    "    def decode_forward(self, hc) :\n",
    "        h = hc[0]\n",
    "        h = h.reshape(-1, 13)\n",
    "        y = self.decode_f(h)\n",
    "        return y\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        y, hc = self.encode_forward(x)\n",
    "        y = self.decode_forward(hc)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7532d2-5e14-4cec-8e9c-f0f264ba256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (encode_rnn): LSTM(13, 13, batch_first=True)\n",
      "  (decode_f): Linear(in_features=13, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# torch 불러오기\n",
    "\n",
    "F = torch.load('sound_ai.pt', weights_only=False).to('cpu') #토치 함수 불러오고, cpu로 변환\n",
    "F.eval() #dropout 끄기\n",
    "\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daff9ea2-f519-4043-9afb-8b64e4f1e16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4244: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# torch를 onnx로 변환\n",
    "x = torch.randn(1,1234,13) #더미 입력값\n",
    "dynamic_axes = {'input' : {0 : 'b', 1 : 'f'}, 'output' : {0 : 'b'}} #입력값과 출력값의 가변 차원 (길이가 바뀌어도 계산되는 차원)\n",
    "\n",
    "torch.onnx.export(\n",
    "    F,\n",
    "    x,\n",
    "    'sound_ai.onnx',\n",
    "    export_params = True, #w, b 저장\n",
    "    opset_version = 20,\n",
    "    do_constant_folding = True,\n",
    "    input_names = ['input'],\n",
    "    output_names = ['output'],\n",
    "    dynamic_axes = dynamic_axes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac80360-d6ac-4187-96c8-a9b0fe2b83a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_F = onnx.load('sound_ai.onnx')\n",
    "onnx.checker.check_model(onnx_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db32f9c2-55f0-4733-a223-85df5bb2b55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18746682 -0.6808965   0.4690648   0.48259994 -0.2092566   0.2997513\n",
      "  -0.6299207 ]\n",
      " [ 0.02194116 -0.59072715  0.6736289  -0.05012216  0.07579528 -0.31417677\n",
      "  -0.44111225]]\n",
      "\n",
      "[[ 0.18746684 -0.6808965   0.4690649   0.48259994 -0.20925663  0.29975134\n",
      "  -0.6299208 ]\n",
      " [ 0.02194114 -0.5907271   0.6736288  -0.05012216  0.07579522 -0.3141768\n",
      "  -0.4411122 ]]\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,5,13)\n",
    "numpy_x = x.detach().numpy()\n",
    "\n",
    "onnx_F = onnxruntime.InferenceSession('sound_ai.onnx', providers=['CPUExecutionProvider'])\n",
    "\n",
    "y = F(x)\n",
    "inputs = {onnx_F.get_inputs()[0].name : numpy_x}\n",
    "outputs = onnx_F.run(None, inputs)\n",
    "\n",
    "print(y.detach().numpy())\n",
    "print()\n",
    "print(outputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d462ac6-d915-4c2d-b65c-eb9b4b6729be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
