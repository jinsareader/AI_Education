{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be18d25e-c03a-4357-a653-1c7b5510ef33",
   "metadata": {},
   "source": [
    "# 한국어의 특징\n",
    "\n",
    "## 한국어는 문법상 동사의 활용이 난해하고 조사의 존재 때문에 고립어인 영어보다 형태소 단위로 AI에게 학습시키기 난해하다.\n",
    "## 하지만 영어보다는 문자를 발음할 때의 규칙성이 더 높기 때문에 STT/TTS를 제작할 때는 음절 단위로 학습시키는게 더 유리하다.\n",
    "\n",
    "\n",
    "# 이를 위한 함수 chr(), ord()\n",
    "## ord() : 문자 하나를 유니코드 숫자 값으로 변환시키는 함수\n",
    "#### 예1) ord('A') == 65\n",
    "#### 예2) ord('가') == 0xAC00\n",
    "## chr() : 숫자를 해당 유니코드 숫자 값을 가진 문자 하나로 변환시키는 함수\n",
    "#### 예1) chr(97) == 'a'\n",
    "\n",
    "\n",
    "# 한국어 유니코드 완성형의 특징\n",
    "## 한국어 유니코드는 완성형으로 숫자 값이 배정되어 있으나 숫자값 배정에 규칙이 존재해서 초성, 중성, 종성 분리가 쉽다\n",
    "## 공식 : (초성 * 21 + 중성) * 28 + 종성 + 0xAC00\n",
    "#### 초성 :\n",
    "['ㄱ','ㄲ','ㄴ','ㄷ','ㄸ','ㄹ','ㅁ','ㅂ','ㅃ','ㅅ','ㅆ','ㅇ','ㅈ','ㅉ','ㅊ','ㅋ','ㅌ','ㅍ','ㅎ'] (19개)\n",
    "#### 중성 :\n",
    "['ㅏ','ㅐ','ㅑ','ㅒ','ㅓ','ㅔ','ㅕ','ㅖ','ㅗ','ㅘ','ㅙ','ㅚ','ㅛ','ㅜ','ㅝ','ㅞ','ㅟ','ㅠ','ㅡ','ㅢ','ㅣ'] (21개)\n",
    "#### 종성 : \n",
    "['','ㄱ','ㄲ','ㄳ','ㄴ','ㄵ','ㄶ','ㄷ','ㄹ','ㄺ','ㄻ','ㄼ','ㄽ','ㄾ','ㄿ','ㅀ','ㅁ','ㅂ','ㅄ','ㅅ','ㅆ','ㅇ','ㅈ','ㅊ','ㅋ','ㅌ','ㅍ','ㅎ'] (28개)\n",
    "#### 기타 특문을 위한 라벨링 :\n",
    "['unk','sos','eos',' ','.','!','?','N'] (8개, 가변적)\n",
    "\n",
    "\n",
    "## 이를 위한 Multi-hot-encoding\n",
    "### 기존 One-hot-encoding과 달리 1의 값이 여러개인 인코딩 방식\n",
    "#### 예시로 '건'이라는 글자는\n",
    "#### 앞의 0~18번째 벡터 중 0번째가 1, 나머지가 0\n",
    "#### 중간의 19~39번째 백터 중 23번째가 1, 나머지가 0\n",
    "#### 뒤의 40~67번째 벡터 중 44번째가 1, 나머지가 0\n",
    "#### 위와 같이 표현이 가능하다\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "참고 문헌 : https://koreascience.or.kr/article/CFKO201832073079068.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47dcbca-05d3-43a9-b084-cadb7734d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"\"), \"..\"))\n",
    "\n",
    "import custom\n",
    "import numpy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdab156-4fbd-4222-bc14-58e62283597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "21\n",
      "28\n",
      "8\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cho_list = ['ㄱ','ㄲ','ㄴ','ㄷ','ㄸ','ㄹ','ㅁ','ㅂ','ㅃ','ㅅ','ㅆ','ㅇ','ㅈ','ㅉ','ㅊ','ㅋ','ㅌ','ㅍ','ㅎ']\n",
    "jung_list = ['ㅏ','ㅐ','ㅑ','ㅒ','ㅓ','ㅔ','ㅕ','ㅖ','ㅗ','ㅘ','ㅙ','ㅚ','ㅛ','ㅜ','ㅝ','ㅞ','ㅟ','ㅠ','ㅡ','ㅢ','ㅣ']\n",
    "jong_list = ['','ㄱ','ㄲ','ㄳ','ㄴ','ㄵ','ㄶ','ㄷ','ㄹ','ㄺ','ㄻ','ㄼ','ㄽ','ㄾ','ㄿ','ㅀ','ㅁ','ㅂ','ㅄ','ㅅ','ㅆ','ㅇ','ㅈ','ㅊ','ㅋ','ㅌ','ㅍ','ㅎ']\n",
    "spec_list = ['<sos>','<eos>','<unk>',' ','.','!','?','N']\n",
    "\n",
    "print(len(cho_list))\n",
    "print(len(jung_list))\n",
    "print(len(jong_list))\n",
    "print(len(spec_list))\n",
    "\n",
    "total_len = len(cho_list)+len(jung_list)+len(jong_list)+len(spec_list)\n",
    "print(total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d889317a-7ce1-4385-a579-eb108e06fefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11181\n"
     ]
    }
   ],
   "source": [
    "# 음절-벡터 사전 만들기\n",
    "\n",
    "vec_dict = {}\n",
    "vec_dict[\"<pad>\"] = numpy.zeros(total_len) #pad는 영행렬 고정\n",
    "\n",
    "for i in range(ord('가'), ord('힣') + 1) :\n",
    "    vec = numpy.zeros(total_len)\n",
    "    val = i - 0xAC00\n",
    "    \n",
    "    chosung  = (val // 28) // 21\n",
    "    jungsung = (val // 28) % 21\n",
    "    jongsung = val % 28\n",
    "    \n",
    "    vec[chosung] += 1\n",
    "    vec[jungsung+19] += 1\n",
    "    vec[jongsung+40] += 1\n",
    "\n",
    "    vec_dict[chr(i)] = vec\n",
    "\n",
    "for i in range(len(spec_list)) :\n",
    "    vec = numpy.zeros(total_len)\n",
    "    vec[68 + i] += 1\n",
    "\n",
    "    vec_dict[spec_list[i]] = vec\n",
    "\n",
    "print(len(vec_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f24a803-7033-4f29-80f0-40abbebb60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음절-벡터 사전 저장\n",
    "\n",
    "with open(\"k_sound_vec.pkl\", mode = \"wb\") as f:\n",
    "    pickle.dump(vec_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75221d6c-eefa-4b91-8d5d-2727030fb9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11181\n",
      "(11181, 76)\n"
     ]
    }
   ],
   "source": [
    "# 음절과 벡터 분리해서 저장\n",
    "sound_dict = {}\n",
    "for i in range(len(vec_dict)) :\n",
    "    sound_dict[list(vec_dict.keys())[i]] = i\n",
    "\n",
    "vec_list = numpy.array(list(vec_dict.values()))\n",
    "\n",
    "print(len(sound_dict))\n",
    "print(vec_list.shape)\n",
    "\n",
    "with open(\"k_sound_dict.pkl\", mode = \"wb\") as f:\n",
    "    pickle.dump(sound_dict, f)\n",
    "\n",
    "with open(\"k_vec_list.pkl\", mode = \"wb\") as f:\n",
    "    pickle.dump(vec_list, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91d09e71-b3d6-409e-9532-65f7b6a5f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6473, 1366, 10585, 5433, 6805, 11176, 4121, 18, 5814, 1737, 1765, 11177]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 문장을 음절 라벨, 벡터로 테스트\n",
    "\n",
    "text = \"안녕하세요 반갑습니다.\"\n",
    "sound = list(text)\n",
    "\n",
    "sound_label = custom.word_vectorize(sound, sound_dict)\n",
    "sound_vector = numpy.array(custom.word_vectorize(sound, vec_dict))\n",
    "print(sound_label)\n",
    "print(sound_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c903c5e-f927-4248-a0ba-4bf7d219af80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안', '녕', '하', '세', '요', ' ', '반', '갑', '습', '니', '다', '.']\n",
      "안녕하세요 반갑습니다.\n"
     ]
    }
   ],
   "source": [
    "# 음절 라벨을 문장으로 테스트\n",
    "\n",
    "num_dict = {v : k for k, v in sound_dict.items()}\n",
    "\n",
    "re_text = custom.word_vectorize(sound_label, num_dict)\n",
    "print(re_text)\n",
    "print(\"\".join(re_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88331698-d057-437a-8b76-804f586f5384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
