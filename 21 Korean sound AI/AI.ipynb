{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79225d27-1b2e-4d62-9731-6a1317edbeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # 데이터 불러오는 용도 (벡터 리스트, 전처리 자료들 불러오는 용도)\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f10a50-c05d-4c7b-af7b-d3bc97dea9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11181, 76])\n"
     ]
    }
   ],
   "source": [
    "# 벡터 리스트 불러오기\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with open(\"sound_vector_list.pkl\", mode = \"rb\") as f:\n",
    "    vectors = torch.tensor(pickle.load(f), dtype = torch.float, device = device)\n",
    "with open(\"sound_dict.pkl\", mode = \"rb\") as f:\n",
    "    sound_dict = pickle.load(f)\n",
    "\n",
    "print(vectors.shape)\n",
    "pad_idx = sound_dict[\"<pad>\"]\n",
    "sos_idx = sound_dict[\"<sos>\"]\n",
    "eos_idx = sound_dict[\"<eos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e09ca1-7bf6-424c-91f9-08aee8652f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10002, 196, 64])\n",
      "torch.Size([10002, 6])\n",
      "torch.Size([1250, 182, 64])\n",
      "torch.Size([1250, 6])\n",
      "101\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "def dataload(x_file_name, t_file_name, batch_size, shuffle, device) :\n",
    "    with open(x_file_name, mode = \"rb\") as f:\n",
    "        tensor_x = torch.tensor(pickle.load(f), dtype = torch.float, device = device)\n",
    "        print(tensor_x.shape)\n",
    "    with open(t_file_name, mode = \"rb\") as f:\n",
    "        tensor_t = torch.tensor(pickle.load(f), dtype = torch.long, device = device)\n",
    "        print(tensor_t.shape)\n",
    "    return DataLoader(list(zip(tensor_x, tensor_t)), batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_dataloader = dataload(\"data/sound_data_train.pkl\", \"data/text_data_train.pkl\", 100, True, device)\n",
    "test_dataloader = dataload(\"data/sound_data_test.pkl\", \"data/text_data_test.pkl\", 100, True, device)\n",
    "\n",
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a52df1-6a6d-41c1-99a1-9989470d33c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경만 미리 만들어 놓은거 불러오기\n",
    "\n",
    "from NN import Encoder\n",
    "from NN import Attention\n",
    "from NN import Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a53852d-2cdc-4062-b5ff-3389c12caed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | loss 3.789317780201978 | acc 0.31575262543757293 | cnt 0\n",
      "epoch 1 | loss 2.7851523892714245 | acc 0.40233372228704783 | cnt 0\n",
      "epoch 2 | loss 2.039760982636178 | acc 0.5439906651108518 | cnt 0\n",
      "epoch 3 | loss 1.4886220793912905 | acc 0.6224037339556593 | cnt 0\n",
      "epoch 4 | loss 1.1296302658496518 | acc 0.6865810968494749 | cnt 0\n",
      "epoch 5 | loss 0.8852840160379315 | acc 0.7176196032672112 | cnt 0\n",
      "epoch 6 | loss 0.7874724084492957 | acc 0.7388564760793466 | cnt 0\n",
      "epoch 7 | loss 0.6069534226588094 | acc 0.7542590431738623 | cnt 0\n",
      "epoch 8 | loss 0.4897121382268644 | acc 0.784830805134189 | cnt 0\n",
      "epoch 9 | loss 0.4181017959767049 | acc 0.7717619603267212 | cnt 1\n",
      "epoch 10 | loss 0.718812396657644 | acc 0.7568261376896149 | cnt 2\n",
      "epoch 11 | loss 0.42295567285601454 | acc 0.7722287047841306 | cnt 3\n",
      "epoch 12 | loss 0.35812473518423515 | acc 0.7922987164527421 | cnt 0\n",
      "epoch 13 | loss 0.31275543600025746 | acc 0.7969661610268378 | cnt 0\n",
      "epoch 14 | loss 0.3109368655351129 | acc 0.8025670945157526 | cnt 0\n",
      "epoch 15 | loss 0.23978773995975752 | acc 0.8093348891481914 | cnt 0\n",
      "epoch 16 | loss 0.23012378102740144 | acc 0.8070011668611435 | cnt 1\n",
      "epoch 17 | loss 0.17519949197695397 | acc 0.8161026837806301 | cnt 0\n",
      "epoch 18 | loss 0.1689562995798222 | acc 0.7941656942823804 | cnt 1\n",
      "epoch 19 | loss 0.17845094371771458 | acc 0.7995332555425905 | cnt 2\n",
      "epoch 20 | loss 0.2049893218987059 | acc 0.8091015169194866 | cnt 3\n",
      "epoch 21 | loss 0.2012020935959155 | acc 0.808634772462077 | cnt 4\n",
      "epoch 22 | loss 0.1988320168070864 | acc 0.803267211201867 | cnt 5\n",
      "train stopped\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder = Encoder(64, vectors.shape[1], num_layers=2, dropout_p=0.1, bidirectional=True)\n",
    "decoder = Decoder(vectors, vectors.shape[1], num_layers=2, dropout_p=0.1, bidirectional=True, max_len=6, pad_idx=pad_idx, sos_idx=sos_idx)\n",
    "encoder.to(device) # 신경망 gpu로 재지정\n",
    "decoder.to(device)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=pad_idx) # ignore_index 파라미터, t값이 해당값인 경우는 역전파 하지 않겠다는 뜻 (= 미분 x, 함수를 바꾸지 않겠다)\n",
    "encoder_optim = torch.optim.Adam(encoder.parameters(), lr = 0.01)\n",
    "decoder_optim = torch.optim.Adam(decoder.parameters(), lr = 0.02)\n",
    "epoch = 100\n",
    "prev_acc = 0\n",
    "cnt = 0\n",
    "\n",
    "for e in range(epoch) :\n",
    "    loss_sum = 0\n",
    "    encoder.train() # 드롭아웃 켜주기\n",
    "    decoder.train()\n",
    "    for x, t in train_dataloader :\n",
    "        # 순전파\n",
    "        y, h, c = encoder(x)\n",
    "        y, h, c = decoder(y, h, c)\n",
    "        # 손실함수 계산\n",
    "        loss = loss_function(y.reshape(-1, y.shape[-1]), t.reshape(-1))\n",
    "        loss_sum += loss.item()\n",
    "        # 역전파\n",
    "        decoder_optim.zero_grad()\n",
    "        encoder_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        decoder_optim.step()\n",
    "        encoder_optim.step()\n",
    "    loss_sum /= len(train_dataloader)\n",
    "    # 중간 acc 점검\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    encoder.eval() # 드롭아웃 꺼주기\n",
    "    decoder.eval()\n",
    "    for x, t in test_dataloader :\n",
    "        with torch.no_grad() : #미분계산을 안하기 때문에 계산이 조금 더 빨라진다. (안 넣어도 문제는 없습니다)\n",
    "            mask = (t != pad_idx) # y와 t를 비교할 때, <pad>값이 아닌 값들만 비교해야 하니까 이를 위한 mask\n",
    "\n",
    "            y, h, c = encoder(x)\n",
    "            y, h, c = decoder(y, h, c)\n",
    "            correct += (y.argmax(dim=-1)[mask] == t[mask]).sum().item()\n",
    "            total += mask.sum().item()\n",
    "    acc = correct / total\n",
    "    # earlystopper\n",
    "    if acc <= prev_acc + 0.001 :\n",
    "        cnt += 1\n",
    "    else :\n",
    "        cnt = 0\n",
    "        prev_acc = acc\n",
    "        torch.save(encoder, \"encoder.pt\")\n",
    "        torch.save(decoder, \"decoder.pt\")\n",
    "    print(f\"epoch {e} | loss {loss_sum} | acc {acc} | cnt {cnt}\")\n",
    "    if cnt >= 5 :\n",
    "        print(\"train stopped\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3047dc25-ad56-4e5f-8f2c-57e8ea999cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu로 저장 된 것을 다시 불러와서 cpu로 재저장\n",
    "\n",
    "encoder = torch.load(\"encoder.pt\", weights_only=False, map_location=\"cpu\")\n",
    "decoder = torch.load(\"decoder.pt\", weights_only=False, map_location=\"cpu\")\n",
    "\n",
    "torch.save(encoder, \"encoder.pt\")\n",
    "torch.save(decoder, \"decoder.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
