{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0df0766-1758-4748-894f-e9a3a269b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI 만들기\n",
    "\n",
    "# 데이터 불러오기 (학습 데이터 자료, 벡터 리스트, 단어-라벨링 사전) (pandas, pickle, custom.word_vectorize, numpy)\n",
    "# x, t 분리\n",
    "# 데이터 단어 라벨링\n",
    "# Dataloader에 싣기 (torch, math) \n",
    "# 신경망 제작 (NN.py) #transformer 구조로 신경망 제작\n",
    "# 신경망 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8f9b42-b896-4f8d-b6a7-e9149decd703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"\"),\"..\"))\n",
    "import custom\n",
    "\n",
    "from IPython.display import display\n",
    "import pandas\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef54da-dfde-4bca-a607-8a3f77f9bdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30187, 200)\n"
     ]
    }
   ],
   "source": [
    "# 벡터, 사전 불러오기\n",
    "with open(\"../15 Movies_Korean/data/korean_vector_list.pkl\", mode = \"rb\") as f :\n",
    "    vector = pickle.load(f)\n",
    "with open(\"../15 Movies_Korean/data/korean_word.pkl\", mode = \"rb\") as f:\n",
    "    word_dict = pickle.load(f)\n",
    "\n",
    "vector = np.array(vector)\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19b7b2e2-6696-4ae3-b5eb-f89d4aef801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_len</th>\n",
       "      <th>mood_공포</th>\n",
       "      <th>mood_놀람</th>\n",
       "      <th>mood_분노</th>\n",
       "      <th>mood_슬픔</th>\n",
       "      <th>mood_중립</th>\n",
       "      <th>mood_행복</th>\n",
       "      <th>mood_혐오</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>언니 동생 으로 부르 는 것 이 맞 는 일 이 ㄴ가 요 ?</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그냥 나 의 느낌 이 ㄹ 뿐 겠 지 ?</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아직 너무 초기 이 라서 그런 거 이 죠 ?</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>유치원 버스 사고 나 엇 다던데</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>근데 원래 이런 거 맞 나 요</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94189</th>\n",
       "      <td>얘기 ㄴ 다 끝나 었 냐 ? 원예 부</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94190</th>\n",
       "      <td>예 . 그거 때문 에 부탁 이 있 . 는 . 데 요 .</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94191</th>\n",
       "      <td>여자 숨기 어 달 라는 거 이 면 사절 이 다 .</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94192</th>\n",
       "      <td>아무래도 안 되 나 요 ?</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94193</th>\n",
       "      <td>그 여자 랑 나 가 무슨 상관 이 ㄴ데 ? 아까 는 탐정 님 이 부탁 하 기에 너 ...</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94194 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  word_len  mood_공포  \\\n",
       "0                       언니 동생 으로 부르 는 것 이 맞 는 일 이 ㄴ가 요 ?        14     True   \n",
       "1                                  그냥 나 의 느낌 이 ㄹ 뿐 겠 지 ?        10     True   \n",
       "2                               아직 너무 초기 이 라서 그런 거 이 죠 ?        10     True   \n",
       "3                                      유치원 버스 사고 나 엇 다던데         6     True   \n",
       "4                                       근데 원래 이런 거 맞 나 요         7     True   \n",
       "...                                                  ...       ...      ...   \n",
       "94189                               얘기 ㄴ 다 끝나 었 냐 ? 원예 부         9    False   \n",
       "94190                     예 . 그거 때문 에 부탁 이 있 . 는 . 데 요 .        14    False   \n",
       "94191                        여자 숨기 어 달 라는 거 이 면 사절 이 다 .        12    False   \n",
       "94192                                     아무래도 안 되 나 요 ?         6    False   \n",
       "94193  그 여자 랑 나 가 무슨 상관 이 ㄴ데 ? 아까 는 탐정 님 이 부탁 하 기에 너 ...        35    False   \n",
       "\n",
       "       mood_놀람  mood_분노  mood_슬픔  mood_중립  mood_행복  mood_혐오  \n",
       "0        False    False    False    False    False    False  \n",
       "1        False    False    False    False    False    False  \n",
       "2        False    False    False    False    False    False  \n",
       "3        False    False    False    False    False    False  \n",
       "4        False    False    False    False    False    False  \n",
       "...        ...      ...      ...      ...      ...      ...  \n",
       "94189    False    False    False     True    False    False  \n",
       "94190    False    False    False     True    False    False  \n",
       "94191    False    False    False     True    False    False  \n",
       "94192    False    False    False     True    False    False  \n",
       "94193    False    False    False     True    False    False  \n",
       "\n",
       "[94194 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#학습 데이터 불러오기\n",
    "\n",
    "df = pandas.read_csv(\"mood.csv\", encoding = \"UTF8\", sep = \"\\t\")\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f312bfa5-b662-4ae5-a36e-d7c415aa8bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([94193, 30])\n",
      "torch.Size([94193])\n",
      "tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0, 11929,   136,    12,    45,   213,  6913],\n",
      "       device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# x와 t로 나누고, x는 단어 라벨링, t는 argmax()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "df = df[df['word_len'] > 0]\n",
    "\n",
    "df_x = df['text'].values.tolist() #list로 변환\n",
    "for i in range(len(df_x)) :\n",
    "    df_x[i] = custom.word_vectorize(df_x[i], word_dict, 30)\n",
    "tensor_x = torch.tensor(df_x, dtype = torch.long, device = device)\n",
    "\n",
    "print(tensor_x.shape)\n",
    "\n",
    "\n",
    "df_t = df.iloc[:,2:].values #numpy로 변환\n",
    "df_t = np.argmax(df_t, axis = -1) #argmax 구하고\n",
    "tensor_t = torch.tensor(df_t, dtype = torch.long, device = device)\n",
    "\n",
    "print(tensor_t.shape)\n",
    "\n",
    "print(tensor_x[94191])\n",
    "print(tensor_t[94191])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046e96a1-4a34-4953-8f96-5710a7630847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader에 싣기\n",
    "\n",
    "dataloader = DataLoader(list(zip(tensor_x, tensor_t)), batch_size=200, shuffle = True)\n",
    "test_dataloader = DataLoader(list(zip(tensor_x, tensor_t)), batch_size=1000, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1538b65-f52e-4719-8e80-fb40d93be9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ai 만들기 NN.py에서 만들었습니다\n",
    "\n",
    "from NN import PositionEncoding\n",
    "from NN import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad708ab6-9844-4818-beec-9103ecd5ab55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | loss 1.2471818987224765 | acc 0.588504453621819 | cnt 0\n",
      "epoch 2 | loss 1.1602985210985641 | acc 0.6052891403819817 | cnt 0\n",
      "epoch 3 | loss 1.13007237374656 | acc 0.6166594120582208 | cnt 0\n",
      "epoch 4 | loss 1.1090072428851117 | acc 0.6236026031658404 | cnt 0\n",
      "epoch 5 | loss 1.0955124544236816 | acc 0.6307581242767509 | cnt 0\n",
      "epoch 6 | loss 1.081288174965326 | acc 0.6302591487690168 | cnt 1\n",
      "epoch 7 | loss 1.0683009225851412 | acc 0.6417780514475598 | cnt 0\n",
      "epoch 8 | loss 1.0581389129035286 | acc 0.6324567643030798 | cnt 1\n",
      "epoch 9 | loss 1.0470161722723845 | acc 0.6450160839977493 | cnt 0\n",
      "epoch 10 | loss 1.0353536602038487 | acc 0.6517469451020776 | cnt 0\n",
      "epoch 11 | loss 1.0264790004985347 | acc 0.6535623666302167 | cnt 0\n",
      "epoch 12 | loss 1.0176845027129868 | acc 0.6587432187105199 | cnt 0\n",
      "epoch 13 | loss 1.0066958883512298 | acc 0.6613336447506715 | cnt 0\n",
      "epoch 14 | loss 0.998049798285126 | acc 0.6688713598675061 | cnt 0\n",
      "epoch 15 | loss 0.9882731189646792 | acc 0.6754960559701889 | cnt 0\n",
      "epoch 16 | loss 0.9770843403101473 | acc 0.673892964445341 | cnt 1\n",
      "epoch 17 | loss 0.9684859213049498 | acc 0.6868344781459345 | cnt 0\n",
      "epoch 18 | loss 0.955386507789547 | acc 0.6905927192041872 | cnt 0\n",
      "epoch 19 | loss 0.9439940743638705 | acc 0.696548575796503 | cnt 0\n",
      "epoch 20 | loss 0.9335412485584332 | acc 0.7022390198847048 | cnt 0\n",
      "epoch 21 | loss 0.9239896223297038 | acc 0.7014958648731859 | cnt 1\n",
      "epoch 22 | loss 0.9148934048199097 | acc 0.7127599715477796 | cnt 0\n",
      "epoch 23 | loss 0.9007910182521601 | acc 0.7170065716136018 | cnt 0\n",
      "epoch 24 | loss 0.8923798605894587 | acc 0.7246610682322465 | cnt 0\n",
      "epoch 25 | loss 0.8772726107048634 | acc 0.7314450118373976 | cnt 0\n",
      "epoch 26 | loss 0.8661043446534759 | acc 0.7356279129022326 | cnt 0\n",
      "epoch 27 | loss 0.8543707947315937 | acc 0.7368275774208275 | cnt 0\n",
      "epoch 28 | loss 0.8436649592312532 | acc 0.7499601881243829 | cnt 0\n",
      "epoch 29 | loss 0.8317125457360739 | acc 0.7517968426528511 | cnt 0\n",
      "epoch 30 | loss 0.8211621862308235 | acc 0.7598016837769261 | cnt 0\n",
      "epoch 31 | loss 0.8091020333539148 | acc 0.7645897253511408 | cnt 0\n",
      "epoch 32 | loss 0.7966003830518945 | acc 0.774070259998089 | cnt 0\n",
      "epoch 33 | loss 0.787180557625562 | acc 0.7789963160744429 | cnt 0\n",
      "epoch 34 | loss 0.7747760814972491 | acc 0.7829244211353286 | cnt 0\n",
      "epoch 35 | loss 0.7666275773331871 | acc 0.7876169142080621 | cnt 0\n",
      "epoch 36 | loss 0.7563681317742463 | acc 0.7948786003206183 | cnt 0\n",
      "epoch 37 | loss 0.7466367740033791 | acc 0.7963224443429979 | cnt 0\n",
      "epoch 38 | loss 0.7371973516834769 | acc 0.803870775959997 | cnt 0\n",
      "epoch 39 | loss 0.72362395178234 | acc 0.8113235590755151 | cnt 0\n",
      "epoch 40 | loss 0.7164908579200696 | acc 0.8154321446391982 | cnt 0\n",
      "epoch 41 | loss 0.7096939227383607 | acc 0.8127249370972365 | cnt 1\n",
      "epoch 42 | loss 0.6979448151183483 | acc 0.8212499867293748 | cnt 0\n",
      "epoch 43 | loss 0.6912265919829124 | acc 0.8243181552769314 | cnt 0\n",
      "epoch 44 | loss 0.6817485948277128 | acc 0.8232458887603112 | cnt 1\n",
      "epoch 45 | loss 0.6736373582463355 | acc 0.8290318813499942 | cnt 0\n",
      "epoch 46 | loss 0.660759623010194 | acc 0.8335438939199303 | cnt 0\n",
      "epoch 47 | loss 0.6560502356025064 | acc 0.8383107024938159 | cnt 0\n",
      "epoch 48 | loss 0.6489081466906643 | acc 0.8387672120008918 | cnt 1\n",
      "epoch 49 | loss 0.6446339050802202 | acc 0.8402322890236005 | cnt 0\n",
      "epoch 50 | loss 0.6337467124507685 | acc 0.8393723525102714 | cnt 1\n",
      "epoch 51 | loss 0.6278307980792538 | acc 0.85099742019046 | cnt 0\n",
      "epoch 52 | loss 0.6202422369057965 | acc 0.8543522342424597 | cnt 0\n",
      "epoch 53 | loss 0.6108986835317753 | acc 0.8563587527735607 | cnt 0\n",
      "epoch 54 | loss 0.6112845637489529 | acc 0.857855679296763 | cnt 0\n",
      "epoch 55 | loss 0.5998884245215454 | acc 0.8634187253829902 | cnt 0\n",
      "epoch 56 | loss 0.5980219210155957 | acc 0.8629834488762435 | cnt 1\n",
      "epoch 57 | loss 0.589399493044349 | acc 0.8618793328591297 | cnt 2\n",
      "epoch 58 | loss 0.5824909896101415 | acc 0.8726126145254955 | cnt 0\n",
      "epoch 59 | loss 0.5735134754464378 | acc 0.8683660144596732 | cnt 1\n",
      "epoch 60 | loss 0.5739601033634947 | acc 0.8735999490407992 | cnt 2\n",
      "epoch 61 | loss 0.5677091867174565 | acc 0.8760842100793053 | cnt 0\n",
      "epoch 62 | loss 0.5578797716497109 | acc 0.8816260231652033 | cnt 0\n",
      "epoch 63 | loss 0.5559536074377169 | acc 0.875086259063837 | cnt 1\n",
      "epoch 64 | loss 0.5465958584139554 | acc 0.8840359687025575 | cnt 0\n",
      "epoch 65 | loss 0.5424759511355381 | acc 0.8860637202339877 | cnt 0\n",
      "epoch 66 | loss 0.5363656020468208 | acc 0.8864989967407344 | cnt 1\n",
      "epoch 67 | loss 0.5302598001217893 | acc 0.8867537927446838 | cnt 2\n",
      "epoch 68 | loss 0.5282071400473325 | acc 0.8895565487881265 | cnt 0\n",
      "epoch 69 | loss 0.523031955628385 | acc 0.8938986973554298 | cnt 0\n",
      "epoch 70 | loss 0.5235848982369571 | acc 0.8915843003195566 | cnt 1\n",
      "epoch 71 | loss 0.5153745117334297 | acc 0.8937819158536197 | cnt 2\n",
      "epoch 72 | loss 0.5107890652876245 | acc 0.8987504379306318 | cnt 0\n",
      "epoch 73 | loss 0.5045826341442748 | acc 0.8977100209145054 | cnt 1\n",
      "epoch 74 | loss 0.504459596237053 | acc 0.8963829583939359 | cnt 2\n",
      "epoch 75 | loss 0.5010192134198109 | acc 0.9000456509507075 | cnt 0\n",
      "epoch 76 | loss 0.4942173574380814 | acc 0.901372713471277 | cnt 0\n",
      "epoch 77 | loss 0.49501428368744577 | acc 0.9059484250422006 | cnt 0\n",
      "epoch 78 | loss 0.488170952364138 | acc 0.8950771288736955 | cnt 1\n",
      "epoch 79 | loss 0.4873155592100382 | acc 0.8937606828532906 | cnt 2\n",
      "epoch 80 | loss 0.48698997219150486 | acc 0.9090165935897572 | cnt 0\n",
      "epoch 81 | loss 0.4764684032482706 | acc 0.909834064102428 | cnt 1\n",
      "epoch 82 | loss 0.47438337544726716 | acc 0.9071693225611245 | cnt 2\n",
      "epoch 83 | loss 0.4722695908095933 | acc 0.9122333931396176 | cnt 0\n",
      "epoch 84 | loss 0.46949618662491976 | acc 0.9099614621044027 | cnt 1\n",
      "epoch 85 | loss 0.46565038193562985 | acc 0.9134755236588706 | cnt 0\n",
      "epoch 86 | loss 0.460399082258755 | acc 0.9131464121537693 | cnt 1\n",
      "epoch 87 | loss 0.459595447449674 | acc 0.9187200747401612 | cnt 0\n",
      "epoch 88 | loss 0.4580388805036079 | acc 0.9165118427059336 | cnt 1\n",
      "epoch 89 | loss 0.45698448920705514 | acc 0.9106409181149342 | cnt 2\n",
      "epoch 90 | loss 0.45157360290266146 | acc 0.9161721147006677 | cnt 3\n",
      "epoch 91 | loss 0.4471430327355735 | acc 0.9151210811843767 | cnt 4\n",
      "epoch 92 | loss 0.4458391493672778 | acc 0.9166498572080728 | cnt 5\n",
      "train end\n"
     ]
    }
   ],
   "source": [
    "# Ai 학습하기\n",
    "tensor_vector = torch.tensor(vector, dtype = torch.float)\n",
    "encoder = Encoder(tensor_vector, nhead=8, out_n=7, dim_feedforward=1024, dropout_p = 0.1, num_layers=2)\n",
    "encoder.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr = 0.0008)\n",
    "epoch = 100\n",
    "prev_acc = 0\n",
    "cnt = 0\n",
    "\n",
    "for e in range(epoch) :\n",
    "    loss_sum = 0\n",
    "    encoder.train() #dropout 켜주기\n",
    "    for x, t in dataloader :\n",
    "        # 순전파\n",
    "        y = encoder(x)\n",
    "        # 손실함수 계산\n",
    "        loss = loss_function(y, t)\n",
    "        loss_sum += loss.item()\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_sum /= len(dataloader)\n",
    "    # 중간 acc 점검\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    encoder.eval()\n",
    "    for x, t in test_dataloader :\n",
    "        with torch.no_grad() :\n",
    "            y = encoder(x)\n",
    "            correct += (torch.argmax(y, dim = -1) == t).sum().item()\n",
    "            total += len(x)\n",
    "    acc = correct / total\n",
    "    # earlystopper 구현\n",
    "    if acc <= prev_acc + 0.001 :\n",
    "        cnt += 1\n",
    "    else :\n",
    "        cnt = 0\n",
    "        prev_acc = acc\n",
    "        torch.save(encoder, \"encoder.pt\")\n",
    "    print(f\"epoch {e+1} | loss {loss_sum} | acc {acc} | cnt {cnt}\")\n",
    "    if cnt >= 5:\n",
    "        print(\"train end\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621bae46-93cd-4a9d-b80f-ffa96414aa6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
